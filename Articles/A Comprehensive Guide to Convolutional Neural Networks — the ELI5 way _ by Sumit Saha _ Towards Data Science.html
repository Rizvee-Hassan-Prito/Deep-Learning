<!doctype html><html lang="en"><head><title data-rh="true">A Comprehensive Guide to Convolutional Neural Networks — the ELI5 way | by Sumit Saha | Towards Data Science</title><meta data-rh="true" charset="utf-8"/><meta data-rh="true" name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=1"/><meta data-rh="true" name="theme-color" content="#000000"/><meta data-rh="true" name="twitter:app:name:iphone" content="Medium"/><meta data-rh="true" name="twitter:app:id:iphone" content="828256236"/><meta data-rh="true" property="al:ios:app_name" content="Medium"/><meta data-rh="true" property="al:ios:app_store_id" content="828256236"/><meta data-rh="true" property="al:android:package" content="com.medium.reader"/><meta data-rh="true" property="fb:app_id" content="542599432471018"/><meta data-rh="true" property="og:site_name" content="Medium"/><meta data-rh="true" property="og:type" content="article"/><meta data-rh="true" property="article:published_time" content="2018-12-17T05:02:27.450Z"/><meta data-rh="true" name="title" content="A Comprehensive Guide to Convolutional Neural Networks — the ELI5 way | by Sumit Saha | Towards Data Science"/><meta data-rh="true" property="og:title" content="A Comprehensive Guide to Convolutional Neural Networks — the ELI5 way"/><meta data-rh="true" property="al:android:url" content="medium://p/3bd2b1164a53"/><meta data-rh="true" property="al:ios:url" content="medium://p/3bd2b1164a53"/><meta data-rh="true" property="al:android:app_name" content="Medium"/><meta data-rh="true" name="description" content="Artificial Intelligence has been witnessing a monumental growth in bridging the gap between the capabilities of humans and machines. Researchers and enthusiasts alike, work on numerous aspects of the…"/><meta data-rh="true" property="og:description" content="Artificial Intelligence has been witnessing a monumental growth in bridging the gap between the capabilities of humans and machines…"/><meta data-rh="true" property="og:url" content="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53"/><meta data-rh="true" property="al:web:url" content="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53"/><meta data-rh="true" property="og:image" content="https://miro.medium.com/max/1200/1*vkQ0hXDaQv57sALXAJquxA.jpeg"/><meta data-rh="true" property="article:author" content="https://medium.com/@_sumitsaha_"/><meta data-rh="true" name="author" content="Sumit Saha"/><meta data-rh="true" name="robots" content="index,follow,max-image-preview:large"/><meta data-rh="true" name="referrer" content="unsafe-url"/><meta data-rh="true" property="twitter:title" content="A Comprehensive Guide to Convolutional Neural Networks — the ELI5 way"/><meta data-rh="true" name="twitter:site" content="@TDataScience"/><meta data-rh="true" name="twitter:app:url:iphone" content="medium://p/3bd2b1164a53"/><meta data-rh="true" property="twitter:description" content="Artificial Intelligence has been witnessing a monumental growth in bridging the gap between the capabilities of humans and machines…"/><meta data-rh="true" name="twitter:image:src" content="https://miro.medium.com/max/1200/1*vkQ0hXDaQv57sALXAJquxA.jpeg"/><meta data-rh="true" name="twitter:card" content="summary_large_image"/><meta data-rh="true" name="twitter:creator" content="@_sumitsaha_"/><meta data-rh="true" name="twitter:label1" content="Reading time"/><meta data-rh="true" name="twitter:data1" content="7 min read"/><meta data-rh="true" name="twitter:tile:template:testing" content="2"/><meta data-rh="true" name="twitter:tile:image" content="https://miro.medium.com/max/1200/1*vkQ0hXDaQv57sALXAJquxA.jpeg"/><meta data-rh="true" name="twitter:tile:info1:text" content="Sumit Saha"/><meta data-rh="true" name="twitter:tile:info1:icon" content="User"/><meta data-rh="true" name="twitter:tile:info2:text" content="2018-12-17T05:02:27.450Z"/><meta data-rh="true" name="twitter:tile:info2:icon" content="Calendar"/><meta data-rh="true" name="twitter:cta" content="Read on Medium"/><link data-rh="true" rel="icon" href="https://miro.medium.com/fit/c/256/256/1*VzTUkfeGymHP4Bvav-T-lA.png"/><link data-rh="true" rel="search" type="application/opensearchdescription+xml" title="Medium" href="/osd.xml"/><link data-rh="true" rel="apple-touch-icon" sizes="152x152" href="https://miro.medium.com/fit/c/152/152/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="apple-touch-icon" sizes="120x120" href="https://miro.medium.com/fit/c/120/120/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="apple-touch-icon" sizes="76x76" href="https://miro.medium.com/fit/c/76/76/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="apple-touch-icon" sizes="60x60" href="https://miro.medium.com/fit/c/60/60/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="mask-icon" href="https://cdn-static-1.medium.com/_/fp/icons/Medium-Avatar-500x500.svg" color="#171717"/><link data-rh="true" rel="preconnect" href="https://glyph.medium.com" crossOrigin=""/><link data-rh="true" id="glyph_preload_link" rel="preload" as="style" type="text/css" href="https://glyph.medium.com/css/unbound.css"/><link data-rh="true" id="glyph_link" rel="stylesheet" type="text/css" href="https://glyph.medium.com/css/unbound.css"/><link data-rh="true" rel="author" href="https://medium.com/@_sumitsaha_"/><link data-rh="true" rel="canonical" href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53"/><link data-rh="true" rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/3bd2b1164a53"/><script data-rh="true" type="application/ld+json">{"@context":"http:\u002F\u002Fschema.org","@type":"NewsArticle","image":["https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F1200\u002F1*vkQ0hXDaQv57sALXAJquxA.jpeg"],"url":"https:\u002F\u002Ftowardsdatascience.com\u002Fa-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53","dateCreated":"2018-12-15T17:03:34.706Z","datePublished":"2018-12-15T17:03:34.706Z","dateModified":"2021-12-07T02:07:22.226Z","headline":"A Comprehensive Guide to Convolutional Neural Networks — the ELI5 way","name":"A Comprehensive Guide to Convolutional Neural Networks — the ELI5 way","description":"Artificial Intelligence has been witnessing a monumental growth in bridging the gap between the capabilities of humans and machines. Researchers and enthusiasts alike, work on numerous aspects of the…","identifier":"3bd2b1164a53","author":{"@type":"Person","name":"Sumit Saha","url":"https:\u002F\u002Ftowardsdatascience.com\u002F@_sumitsaha_"},"creator":["Sumit Saha"],"publisher":{"@type":"Organization","name":"Towards Data Science","url":"towardsdatascience.com","logo":{"@type":"ImageObject","width":165,"height":60,"url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F330\u002F1*mG6i4Bh_LgixUYXJgQpYsg@2x.png"}},"mainEntityOfPage":"https:\u002F\u002Ftowardsdatascience.com\u002Fa-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53"}</script><style type="text/css" data-fela-rehydration="554" data-fela-type="STATIC">html{box-sizing:border-box}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}:root{--reach-tabs:1;--reach-menu-button:1}#speechify-root{font-family:Sohne, sans-serif}div[data-popper-reference-hidden="true"]{visibility:hidden;pointer-events:none}
/*XCode style (c) Angel Garcia <angelgarcia.mail@gmail.com>*/.hljs {background: #fff;color: black;
}/* Gray DOCTYPE selectors like WebKit */
.xml .hljs-meta {color: #c0c0c0;
}.hljs-comment,
.hljs-quote {color: #007400;
}.hljs-tag,
.hljs-attribute,
.hljs-keyword,
.hljs-selector-tag,
.hljs-literal,
.hljs-name {color: #aa0d91;
}.hljs-variable,
.hljs-template-variable {color: #3F6E74;
}.hljs-code,
.hljs-string,
.hljs-meta .hljs-string {color: #c41a16;
}.hljs-regexp,
.hljs-link {color: #0E0EFF;
}.hljs-title,
.hljs-symbol,
.hljs-bullet,
.hljs-number {color: #1c00cf;
}.hljs-section,
.hljs-meta {color: #643820;
}.hljs-title.class_,
.hljs-class .hljs-title,
.hljs-type,
.hljs-built_in,
.hljs-params {color: #5c2699;
}.hljs-attr {color: #836C28;
}.hljs-subst {color: #000;
}.hljs-formula {background-color: #eee;font-style: italic;
}.hljs-addition {background-color: #baeeba;
}.hljs-deletion {background-color: #ffc8bd;
}.hljs-selector-id,
.hljs-selector-class {color: #9b703f;
}.hljs-doctag,
.hljs-strong {font-weight: bold;
}.hljs-emphasis {font-style: italic;
}
</style><style type="text/css" data-fela-rehydration="554" data-fela-type="KEYFRAME">@-webkit-keyframes k1{0%{transform:scale(1)}50%{transform:scale(1.1)}100%{transform:scale(1)}}@-moz-keyframes k1{0%{transform:scale(1)}50%{transform:scale(1.1)}100%{transform:scale(1)}}@keyframes k1{0%{transform:scale(1)}50%{transform:scale(1.1)}100%{transform:scale(1)}}</style><style type="text/css" data-fela-rehydration="554" data-fela-type="RULE">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.l{display:block}.m{margin:auto}.n{max-width:1504px}.o{display:flex}.u{justify-content:space-between}.ag{height:100%}.al{padding:0 24px}.am{box-shadow:0px -2px 10px rgba(0, 0, 0, 0.15)}.an{height:56px}.ao{align-items:center}.ap{position:fixed}.aq{top:0}.ar{right:0}.as{left:0}.at{z-index:500}.au{color:inherit}.av{fill:inherit}.aw{font-size:inherit}.ax{border:inherit}.ay{font-family:inherit}.az{letter-spacing:inherit}.ba{font-weight:inherit}.bb{padding:0}.bc{margin:0}.bg:disabled{cursor:default}.bh:disabled{color:rgba(117, 117, 117, 1)}.bi:disabled{fill:rgba(117, 117, 117, 1)}.bj{height:25px}.bk{fill:rgba(41, 41, 41, 1)}.bl{text-align:center}.bm{font-family:sohne, "Helvetica Neue", Helvetica, Arial, sans-serif}.bn{font-size:14px}.bo{line-height:20px}.bp{color:rgba(242, 242, 242, 1)}.bq{padding:7px 16px 9px}.br{fill:rgba(242, 242, 242, 1)}.bs{background:rgba(242, 242, 242, 1)}.bt{border-color:rgba(242, 242, 242, 1)}.bz:disabled{cursor:inherit !important}.ca:disabled{opacity:0.1}.cb:disabled:hover{background:rgba(25, 25, 25, 1)}.cc:disabled:hover{border-color:rgba(25, 25, 25, 1)}.cd{border-radius:99em}.ce{width:100%}.cf{border-width:1px}.cg{border-style:solid}.ch{box-sizing:border-box}.ci{display:inline-block}.cj{text-decoration:none}.ck{margin-left:16px}.cl{display:none}.cn{color:rgba(117, 117, 117, 1)}.co{color:rgba(26, 137, 23, 1)}.cp{fill:rgba(26, 137, 23, 1)}.cs:disabled{color:rgba(163, 208, 162, 0.5)}.ct:disabled{fill:rgba(163, 208, 162, 0.5)}.cz{height:100vh}.da{flex-direction:column}.db{position:sticky}.dc{height:23px}.dd{padding-bottom:35px}.de{fill:rgba(117, 117, 117, 1)}.df{padding-left:28px}.dg{transition:all 0.2s ease-in-out}.dk{margin-right:28px}.dm{font-size:16px}.dn{line-height:24px}.do{position:relative}.dp{margin:0px 0px 35px 28px }.dq{width:24px}.dr{border:0}.ds{height:1px}.dt{background-color:rgba(230, 230, 230, 1)}.du{padding:0 24px 24px}.dv{height:64px}.dw path{fill:rgba(168, 168, 168, 1)}.dx{justify-content:center}.dy{flex:1}.dz{border:none}.ea{background:transparent}.eb{box-shadow:0px 2px 10px rgba(0, 0, 0, 0.15)}.ec{z-index:600}.ed{bottom:0}.ee{justify-content:space-around}.ef{height:16px}.eg{background-color:rgba(237, 237, 237, 1)}.em{min-width:0}.en{flex:1 1 auto}.eo{padding:0 32px}.ep{border-left:1px solid rgba(230, 230, 230, 1)}.eq{min-height:100vh}.er{width:394px}.et{color:rgba(102, 138, 170, 1)}.eu{fill:rgba(102, 138, 170, 1)}.ex:disabled{color:rgba(102, 138, 170, 0.5)}.ey:disabled{fill:rgba(102, 138, 170, 0.5)}.ez{border-bottom:1px solid rgba(230, 230, 230, 1)}.fj{margin-right:16px}.fk{box-shadow:inset 0 0 0 1px rgba(0, 0, 0, 0.05)}.fl{border-radius:50%}.fm{height:32px}.fn{width:32px}.fo{position:absolute}.fp{background-color:rgba(242, 242, 242, 1)}.fq{margin-right:3px}.fr{flex:0 0 auto}.fs{overflow:hidden}.ft{max-height:20px}.fu{text-overflow:ellipsis}.fv{display:-webkit-box}.fw{-webkit-line-clamp:1}.fx{-webkit-box-orient:vertical}.fy{word-break:break-all}.ga{color:rgba(41, 41, 41, 1)}.gl{margin-left:auto}.gm{margin-right:auto}.gn{max-width:728px}.gy{align-items:flex-start}.gz{height:48px}.ha{width:48px}.hb{margin-bottom:4px}.hc{flex-direction:row}.hd{padding-left:12px}.hi{font-size:13px}.hj{color:rgba(255, 255, 255, 1)}.hk{padding:0px 8px 1px}.hl{fill:rgba(255, 255, 255, 1)}.hm{background:rgba(102, 138, 170, 1)}.hn{border-color:rgba(102, 138, 170, 1)}.hq:disabled{opacity:0.3}.hr:disabled:hover{background:rgba(102, 138, 170, 1)}.hs:disabled:hover{border-color:rgba(102, 138, 170, 1)}.ht{flex-wrap:wrap}.hu{padding:0 8px}.hy{padding-right:4px}.hz{padding:8px 2px}.ib{margin:0 4px 0 28px}.ic{display:inline-flex}.id{padding-top:24px}.ig{padding-right:12px}.ih{background:rgba(255, 255, 255, 1)}.ii{border:1px solid rgba(230, 230, 230, 1)}.ij{border-radius:4px}.ik{box-shadow:0 1px 4px rgba(230, 230, 230, 1)}.il{max-height:100vh}.im{overflow-y:auto}.in{top:calc(100vh + 100px)}.io{bottom:calc(100vh + 100px)}.ip{width:10px}.iq{pointer-events:none}.ir{word-break:break-word}.is{word-wrap:break-word}.it:after{display:block}.iu:after{content:""}.iv:after{clear:both}.iw{line-height:1.23}.ix{letter-spacing:0}.iy{font-style:normal}.iz{font-weight:700}.ju{margin-bottom:-0.27em}.jv{max-width:1255px}.jz{clear:both}.kb{cursor:zoom-in}.kc{z-index:auto}.ke{max-width:100%}.kf{height:auto}.kg{line-height:1.58}.kh{letter-spacing:-0.004em}.ki{font-family:source-serif-pro, Georgia, Cambria, "Times New Roman", Times, serif}.ld{margin-bottom:-0.46em}.le{line-height:1.18}.lf{letter-spacing:-0.022em}.lg{font-weight:600}.ly{margin-bottom:-0.31em}.lz{max-width:1644px}.me{margin-top:10px}.mh{max-width:425px}.mi{max-width:550px}.mj{max-width:526px}.mk{padding:20px}.ml{overflow-x:auto}.mm{border-radius:0}.mn{font-family:Menlo, Monaco, "Courier New", Courier, monospace}.mo{margin-top:-0.09em}.mp{margin-bottom:-0.09em}.mq{white-space:pre-wrap}.mr{min-width:fit-content}.ms{margin-top:0.91em}.mt{max-width:163px}.mu{max-width:1280px}.mv{max-width:395px}.mw{font-weight:500}.na{box-shadow:inset 0 0 0 1px rgba(230, 230, 230, 1)}.nb{padding:0px}.nc{padding:16px 20px}.ne{max-height:40px}.nf{-webkit-line-clamp:2}.ng{margin-top:8px}.nh{margin-top:12px}.ni{width:160px}.nj{background-image:url(https://miro.medium.com/max/320/0*aanOJtoccyFd7bk_)}.nk{background-origin:border-box}.nl{background-size:cover}.nm{height:167px}.nn{background-position:50% 50%}.no{max-width:396px}.np{max-width:596px}.nq{max-width:802px}.nr{line-height:28px}.ns{letter-spacing:-0.003em}.nw{list-style-type:decimal}.nx{margin-left:30px}.ny{padding-left:0px}.nz{font-size:18px}.of{margin-top:32px}.og{margin-bottom:14px}.oh{padding-bottom:10px}.oi{background-color:rgba(8, 8, 8, 1)}.oj{height:3px}.ok{width:3px}.ol{margin-right:20px}.om{background-image:url(https://miro.medium.com/max/320/0*9DL3pUPHcomdTt5h)}.on{padding:16px 0 0}.oo{border-top:none}.op{height:52px}.oq{max-height:52px}.or{box-sizing:content-box}.os{position:static}.ot{z-index:1}.ou{flex:1 0 auto}.ow{max-width:155px}.oz{margin-right:5px}.pc{-webkit-user-select:none}.pd{cursor:progress}.pg{opacity:0.25}.ph{outline:0}.pi{user-select:none}.pj> svg{pointer-events:none}.pu{margin-left:24px}.pv{margin-top:0px}.pw{cursor:pointer}.px{padding:4px 0}.qa{margin-left:4px}.qb{opacity:1}.qc path{fill:rgba(117, 117, 117, 1)}.qe{margin:0 20px}.qf{background-color:rgba(250, 250, 250, 1)}.qg{padding-bottom:4px}.qh{padding-top:32px}.qn{padding-top:5px}.qo{padding-top:25px}.qp{padding-bottom:96px}.qq{padding-top:40px}.qr{padding-bottom:80px}.qs{padding-bottom:26px}.sc{flex-grow:0}.sd{padding-bottom:8px}.se{margin-bottom:24px}.sf{margin-right:24px}.sg{flex:1 0 0%}.sh{margin-bottom:8px}.si{margin-right:8px}.sj{height:20px}.sk{width:20px}.sl{max-height:60px}.sm{-webkit-line-clamp:3}.sn{width:56px}.so{padding-bottom:100%}.sp{height:0}.sq{border-radius:2px}.sr{padding:30px 0}.ss{margin-bottom:0}.st{min-width:100vw}.su{background-color:rgba(0, 0, 0, 1)}.sz{max-width:1192px}.tc:disabled{color:rgba(255, 255, 255, 0.6)}.td:disabled{fill:rgba(255, 255, 255, 0.45)}.te{height:22px}.tf{margin-top:20px}.tg{color:rgba(255, 255, 255, 0.95)}.ti{background-color:rgba(255, 255, 255, 0.4)}.tj{margin:28px 0 20px}.tk{padding-bottom:0px}.tl{border-bottom:none}.tm{margin-top:40px}.tn{border-radius:20px}.to{width:inherit}.tp{outline:none}.tq{padding:10px 20px 10px 0}.tr{background-color:transparent}.ts::placeholder{color:rgba(117, 117, 117, 1)}.tt{padding:7px 7px 6px 8px}.tu{height:88px}.tv{width:88px}.tw{margin-top:16px}.tx{margin-top:4px}.ty{margin-top:24px}.tz{margin-bottom:40px}.ua{width:auto}.ub{margin-left:8px}.uc{stroke:rgba(242, 242, 242, 1)}.ud{height:36px}.ue{width:36px}.uf{padding:24px 0}.ug{margin-right:6px}.uh{font-size:11px}.ui{line-height:16px}.bd:hover{cursor:pointer}.be:hover{color:rgba(25, 25, 25, 1)}.bf:hover{fill:rgba(25, 25, 25, 1)}.bu:hover{background:rgba(242, 242, 242, 1)}.bv:hover{border-color:rgba(242, 242, 242, 1)}.bw:hover{cursor:wait}.bx:hover{color:rgba(242, 242, 242, 1)}.by:hover{fill:rgba(242, 242, 242, 1)}.cq:hover{color:rgba(15, 115, 12, 1)}.cr:hover{fill:rgba(15, 115, 12, 1)}.dh:hover{color:rgba(41, 41, 41, 1)}.di:hover{fill:rgba(41, 41, 41, 1)}.ev:hover{color:rgba(90, 118, 144, 1)}.ew:hover{fill:rgba(90, 118, 144, 1)}.ho:hover{background:rgba(90, 118, 144, 1)}.hp:hover{border-color:rgba(90, 118, 144, 1)}.ia:hover path{fill:rgba(8, 8, 8, 1)}.pf:hover{fill:rgba(117, 117, 117, 1)}.py:hover{fill:rgba(8, 8, 8, 1)}.pz:hover p{color:rgba(8, 8, 8, 1)}.ta:hover{color:rgba(255, 255, 255, 1)}.tb:hover{fill:rgba(255, 255, 255, 0.9)}.th:hover{text-decoration:underline}.kd:focus{transform:scale(1.01)}.pe:focus{fill:rgba(117, 117, 117, 1)}.qd:focus path{fill:rgba(8, 8, 8, 1)}.pk:active{border-style:none}</style><style type="text/css" data-fela-rehydration="554" data-fela-type="RULE" media="all and (min-width: 1080px)">.d{display:none}.t{flex-direction:row}.z{width:80px}.ab{min-height:100vh}.ac{flex-shrink:1}.ae{border-right:1px solid rgba(230, 230, 230, 1)}.cu{display:block}.cv{text-align:center}.cw{padding:40px 0}.el{margin-bottom:0}.fg{margin:0 32px}.fh{max-width:692px}.gf{margin-bottom:40px}.gk{padding:0 16px}.gw{margin-bottom:32px}.gx{margin-top:56px}.hx{display:inline-flex}.jq{font-size:32px}.jr{margin-top:0.6em}.js{line-height:40px}.jt{letter-spacing:-0.016em}.jy{margin-top:40px}.kz{font-size:20px}.la{margin-top:2em}.lb{line-height:32px}.lc{letter-spacing:-0.003em}.lv{margin-top:2.37em}.lw{line-height:24px}.lx{letter-spacing:0}.mz{margin-top:32px}.nv{margin-top:2.14em}.oe{margin-top:1.14em}.pr{margin-top:0px}.pt{display:inline-block}.qm{max-height:24px}.rf{width:calc(100% + 64px)}.rg{margin-left:-32px}.rh{margin-right:-32px}.ry{padding-left:32px}.rz{padding-right:32px}.sa{flex-basis:50%}.sb{max-width:50%}.sy{margin:0 64px}</style><style type="text/css" data-fela-rehydration="554" data-fela-type="RULE" media="all and (max-width: 1079.98px)">.e{display:none}.mf{margin-left:auto}.mg{text-align:center}.pq{margin-top:0px}.ps{display:inline-block}</style><style type="text/css" data-fela-rehydration="554" data-fela-type="RULE" media="all and (max-width: 903.98px)">.f{display:none}.oy{display:inline-block}.pp{margin-top:0px}</style><style type="text/css" data-fela-rehydration="554" data-fela-type="RULE" media="all and (max-width: 727.98px)">.g{display:none}.cm{display:block}.nd{padding:10px 12px 10px}.ox{display:inline-block}.pn{margin-top:0px}.po{margin-right:0px}.sv{padding:24px 0}</style><style type="text/css" data-fela-rehydration="554" data-fela-type="RULE" media="all and (max-width: 551.98px)">.h{display:none}.p{flex-direction:column}.v{width:auto}.ah{display:block}.eh{margin-bottom:56px}.fa{margin:0 24px}.gb{margin-bottom:80px}.gg{padding:0 8px}.go{margin-bottom:24px}.gp{margin-top:32px}.he{display:inline-block}.ie{display:flex}.ja{font-size:32px}.jb{margin-top:0.64em}.jc{line-height:40px}.jd{letter-spacing:-0.016em}.kj{font-size:18px}.kk{margin-top:1.56em}.kl{line-height:28px}.km{letter-spacing:-0.003em}.lh{font-size:16px}.li{margin-top:2.07em}.lj{line-height:20px}.lk{letter-spacing:0}.ma{margin-top:40px}.mx{margin-top:24px}.oa{margin-top:1.34em}.pa{margin-left:0px}.pl{margin-top:0px}.pm{margin-right:0px}.qi{max-height:20px}.qt{width:calc(100% + 24px)}.qu{margin-left:-12px}.qv{margin-right:-12px}.ri{padding-left:12px}.rj{padding-right:12px}.rk{flex-basis:100%}.rl{max-width:100%}</style><style type="text/css" data-fela-rehydration="554" data-fela-type="RULE" media="all and (min-width: 904px) and (max-width: 1079.98px)">.i{display:none}.s{flex-direction:column}.y{width:auto}.ak{display:block}.ek{margin-bottom:56px}.fe{margin:0 32px}.ff{max-width:692px}.ge{margin-bottom:40px}.gj{padding:0 16px}.gu{margin-bottom:24px}.gv{margin-top:32px}.hh{display:inline-block}.hw{display:inline-flex}.jm{font-size:32px}.jn{margin-top:0.6em}.jo{line-height:40px}.jp{letter-spacing:-0.016em}.jx{margin-top:40px}.kv{font-size:20px}.kw{margin-top:2em}.kx{line-height:32px}.ky{letter-spacing:-0.003em}.ls{margin-top:2.37em}.lt{line-height:24px}.lu{letter-spacing:0}.md{margin-top:56px}.nu{margin-top:2.14em}.od{margin-top:1.14em}.ql{max-height:24px}.rc{width:calc(100% + 64px)}.rd{margin-left:-32px}.re{margin-right:-32px}.ru{padding-left:32px}.rv{padding-right:32px}.rw{flex-basis:50%}.rx{max-width:50%}.sx{margin:0 64px}</style><style type="text/css" data-fela-rehydration="554" data-fela-type="RULE" media="all and (min-width: 728px) and (max-width: 903.98px)">.j{display:none}.r{flex-direction:column}.x{width:auto}.aj{display:block}.ej{margin-bottom:56px}.fc{margin:0 32px}.fd{max-width:692px}.gd{margin-bottom:40px}.gi{padding:0 16px}.gs{margin-bottom:24px}.gt{margin-top:32px}.hg{display:inline-block}.hv{display:inline-flex}.ji{font-size:32px}.jj{margin-top:0.6em}.jk{line-height:40px}.jl{letter-spacing:-0.016em}.jw{margin-top:40px}.kr{font-size:20px}.ks{margin-top:2em}.kt{line-height:32px}.ku{letter-spacing:-0.003em}.lp{margin-top:2.37em}.lq{line-height:24px}.lr{letter-spacing:0}.mc{margin-top:56px}.nt{margin-top:2.14em}.oc{margin-top:1.14em}.qk{max-height:24px}.qz{width:calc(100% + 64px)}.ra{margin-left:-32px}.rb{margin-right:-32px}.rq{padding-left:32px}.rr{padding-right:32px}.rs{flex-basis:50%}.rt{max-width:50%}.sw{margin:0 48px}</style><style type="text/css" data-fela-rehydration="554" data-fela-type="RULE" media="all and (min-width: 552px) and (max-width: 727.98px)">.k{display:none}.q{flex-direction:column}.w{width:auto}.ai{display:block}.ei{margin-bottom:56px}.fb{margin:0 24px}.gc{margin-bottom:80px}.gh{padding:0 8px}.gq{margin-bottom:24px}.gr{margin-top:32px}.hf{display:inline-block}.if{display:flex}.je{font-size:32px}.jf{margin-top:0.64em}.jg{line-height:40px}.jh{letter-spacing:-0.016em}.kn{font-size:18px}.ko{margin-top:1.56em}.kp{line-height:28px}.kq{letter-spacing:-0.003em}.ll{font-size:16px}.lm{margin-top:2.07em}.ln{line-height:20px}.lo{letter-spacing:0}.mb{margin-top:40px}.my{margin-top:24px}.ob{margin-top:1.34em}.pb{margin-left:0px}.qj{max-height:20px}.qw{width:calc(100% + 64px)}.qx{margin-left:-32px}.qy{margin-right:-32px}.rm{padding-left:32px}.rn{padding-right:32px}.ro{flex-basis:50%}.rp{max-width:50%}</style><style type="text/css" data-fela-rehydration="554" data-fela-type="RULE" media="print">.ov{display:none}</style><style type="text/css" data-fela-rehydration="554" data-fela-type="RULE" media="all and (min-width: 7000px)">.af{width:224px}.cx{text-align:left}.cy{padding:40px 24px}.dj{display:none}.dl{display:block}.fi{margin:0 auto}</style><style type="text/css" data-fela-rehydration="554" data-fela-type="RULE" media="all and (max-width: 1239.98px)">.es{width:280px}</style><style type="text/css" data-fela-rehydration="554" data-fela-type="RULE" media="(orientation: landscape) and (max-width: 903.98px)">.fz{max-height:none}</style><style type="text/css" data-fela-rehydration="554" data-fela-type="RULE" media="(prefers-reduced-motion: no-preference)">.ka{transition:transform 300ms cubic-bezier(0.2, 0, 0.2, 1)}</style></head><body><div id="root"><div class="a b c"><div class="d e f g h i j k"></div><script>document.domain = document.domain;</script><div class="l c"><div class="m n l"><div class="o p q r s t u"><div class="v w x y z ab ac ae af"><nav class="ag"><div class="ah ai aj ak d"><div class="al am an o ao u ap aq ar as at c"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" aria-label="Homepage" href="https://medium.com/?source=---three_column_layout_nav----------------------------------" rel="noopener follow"><svg viewBox="0 0 1043.63 592.71" class="bj bk"><g data-name="Layer 2"><g data-name="Layer 1"><path d="M588.67 296.36c0 163.67-131.78 296.35-294.33 296.35S0 460 0 296.36 131.78 0 294.34 0s294.33 132.69 294.33 296.36M911.56 296.36c0 154.06-65.89 279-147.17 279s-147.17-124.94-147.17-279 65.88-279 147.16-279 147.17 124.9 147.17 279M1043.63 296.36c0 138-23.17 249.94-51.76 249.94s-51.75-111.91-51.75-249.94 23.17-249.94 51.75-249.94 51.76 111.9 51.76 249.94"></path></g></g></svg></a><div class="o ao"><div class="l bl"><div><a class="bm b bn bo bp bq br bs bt bu bv bw bx by bz ca cb cc cd ce cf cg ch ci cj" href="https://medium.com/plans?source=upgrade_membership---three_column_layout_nav----------------------------------" rel="noopener follow">Get unlimited access</a></div></div><div class="ck cl cm"><span class="bm b bn bo cn"><a class="et eu aw ax ay az ba bb bc bd ev ew bg ex ey" href="https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F3bd2b1164a53&amp;%7Efeature=LoOpenInAppButton&amp;%7Echannel=ShowPostUnderCollection&amp;%7Estage=mobileNavBar&amp;source=---three_column_layout_nav----------------------------------" rel="noopener follow">Open in app</a></span></div></div></div><div class="an l"></div></div><div class="ag h k j i cu"><div class="cz o da u db aq at c"><div class="cv cw cx cy"><a aria-label="Homepage" href="https://medium.com/?source=---three_column_layout_nav----------------------------------" rel="noopener follow"><svg viewBox="0 0 1043.63 592.71" class="dc bk"><g data-name="Layer 2"><g data-name="Layer 1"><path d="M588.67 296.36c0 163.67-131.78 296.35-294.33 296.35S0 460 0 296.36 131.78 0 294.34 0s294.33 132.69 294.33 296.36M911.56 296.36c0 154.06-65.89 279-147.17 279s-147.17-124.94-147.17-279 65.88-279 147.16-279 147.17 124.9 147.17 279M1043.63 296.36c0 138-23.17 249.94-51.76 249.94s-51.75-111.91-51.75-249.94 23.17-249.94 51.75-249.94 51.76 111.9 51.76 249.94"></path></g></g></svg></a></div><div class="l"><div class="dd l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/?source=---three_column_layout_nav----------------------------------" rel="noopener follow"><div class="o do"><div class="cn de o df dg dh di"><div class="l dj dk"><div><div class="ci" aria-hidden="false"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Home"><path d="M4.5 10.75v10.5c0 .14.11.25.25.25h5c.14 0 .25-.11.25-.25v-5.5c0-.14.11-.25.25-.25h3.5c.14 0 .25.11.25.25v5.5c0 .14.11.25.25.25h5c.14 0 .25-.11.25-.25v-10.5M22 9l-9.1-6.83a1.5 1.5 0 0 0-1.8 0L2 9" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></div></div><div class="cl dl dk" aria-hidden="true"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Home"><path d="M4.5 10.75v10.5c0 .14.11.25.25.25h5c.14 0 .25-.11.25-.25v-5.5c0-.14.11-.25.25-.25h3.5c.14 0 .25.11.25.25v5.5c0 .14.11.25.25.25h5c.14 0 .25-.11.25-.25v-10.5M22 9l-9.1-6.83a1.5 1.5 0 0 0-1.8 0L2 9" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"></path></svg></div><div class="cl dl bm b dm dn">Home</div></div></div></a></div><span><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fme%2Fnotifications&amp;source=---three_column_layout_nav-----------------------notifications_sidenav-----------" rel="noopener follow"><div class="dd l"><div class="o do"><div class="cn de o df dg dh di"><div class="l dj dk"><div><div class="ci" aria-hidden="false"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Notifications"><path d="M15 18.5a3 3 0 1 1-6 0" stroke="currentColor" stroke-linecap="round"></path><path d="M5.5 10.53V9a6.5 6.5 0 0 1 13 0v1.53c0 1.42.56 2.78 1.57 3.79l.03.03c.26.26.4.6.4.97v2.93c0 .14-.11.25-.25.25H3.75a.25.25 0 0 1-.25-.25v-2.93c0-.37.14-.71.4-.97l.03-.03c1-1 1.57-2.37 1.57-3.79z" stroke="currentColor" stroke-linejoin="round"></path></svg></div></div></div><div class="cl dl dk" aria-hidden="true"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Notifications"><path d="M15 18.5a3 3 0 1 1-6 0" stroke="currentColor" stroke-linecap="round"></path><path d="M5.5 10.53V9a6.5 6.5 0 0 1 13 0v1.53c0 1.42.56 2.78 1.57 3.79l.03.03c.26.26.4.6.4.97v2.93c0 .14-.11.25-.25.25H3.75a.25.25 0 0 1-.25-.25v-2.93c0-.37.14-.71.4-.97l.03-.03c1-1 1.57-2.37 1.57-3.79z" stroke="currentColor" stroke-linejoin="round"></path></svg></div><div class="cl dl bm b dm dn">Notifications</div></div></div></div></a></span><span><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fme%2Flists&amp;source=---three_column_layout_nav-----------------------lists_sidenav-----------" rel="noopener follow"><div class="dd l"><div class="o do"><div class="cn de o df dg dh di"><div class="l dj dk"><div><div class="ci" aria-hidden="false"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Lists"><path d="M4.5 6.25V21c0 .2.24.32.4.2l5.45-4.09a.25.25 0 0 1 .3 0l5.45 4.09c.16.12.4 0 .4-.2V6.25a.25.25 0 0 0-.25-.25H4.75a.25.25 0 0 0-.25.25z" stroke="currentColor" stroke-linecap="round"></path><path d="M8 6V3.25c0-.14.11-.25.25-.25h11.5c.14 0 .25.11.25.25V16.5" stroke="currentColor" stroke-linecap="round"></path></svg></div></div></div><div class="cl dl dk" aria-hidden="true"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Lists"><path d="M4.5 6.25V21c0 .2.24.32.4.2l5.45-4.09a.25.25 0 0 1 .3 0l5.45 4.09c.16.12.4 0 .4-.2V6.25a.25.25 0 0 0-.25-.25H4.75a.25.25 0 0 0-.25.25z" stroke="currentColor" stroke-linecap="round"></path><path d="M8 6V3.25c0-.14.11-.25.25-.25h11.5c.14 0 .25.11.25.25V16.5" stroke="currentColor" stroke-linecap="round"></path></svg></div><div class="cl dl bm b dm dn">Lists</div></div></div></div></a></span><span><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fme%2Fstories%2Fdrafts&amp;source=---three_column_layout_nav-----------------------stories_sidenav-----------" rel="noopener follow"><div class="dd l"><div class="o do"><div class="cn de o df dg dh di"><div class="l dj dk"><div><div class="ci" aria-hidden="false"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Stories"><path d="M4.75 21.5h14.5c.14 0 .25-.11.25-.25V2.75a.25.25 0 0 0-.25-.25H4.75a.25.25 0 0 0-.25.25v18.5c0 .14.11.25.25.25z" stroke="currentColor"></path><path d="M8 8.5h8M8 15.5h5M8 12h8" stroke="currentColor" stroke-linecap="round"></path></svg></div></div></div><div class="cl dl dk" aria-hidden="true"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Stories"><path d="M4.75 21.5h14.5c.14 0 .25-.11.25-.25V2.75a.25.25 0 0 0-.25-.25H4.75a.25.25 0 0 0-.25.25v18.5c0 .14.11.25.25.25z" stroke="currentColor"></path><path d="M8 8.5h8M8 15.5h5M8 12h8" stroke="currentColor" stroke-linecap="round"></path></svg></div><div class="cl dl bm b dm dn">Stories</div></div></div></div></a></span><div class="dp dq l"><hr class="dr ds dt bc" aria-hidden="true"/></div><span><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fnew-story&amp;source=---three_column_layout_nav-----------------------new_post_sidenav-----------" rel="noopener follow"><div class="dd l"><div class="o do"><div class="cn de o df dg dh di"><div class="l dj dk"><div><div class="ci" aria-hidden="false"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Write"><path d="M14 4a.5.5 0 0 0 0-1v1zm7 6a.5.5 0 0 0-1 0h1zm-7-7H4v1h10V3zM3 4v16h1V4H3zm1 17h16v-1H4v1zm17-1V10h-1v10h1zm-1 1a1 1 0 0 0 1-1h-1v1zM3 20a1 1 0 0 0 1 1v-1H3zM4 3a1 1 0 0 0-1 1h1V3z" fill="currentColor"></path><path d="M17.5 4.5l-8.46 8.46a.25.25 0 0 0-.06.1l-.82 2.47c-.07.2.12.38.31.31l2.47-.82a.25.25 0 0 0 .1-.06L19.5 6.5m-2-2l2.32-2.32c.1-.1.26-.1.36 0l1.64 1.64c.1.1.1.26 0 .36L19.5 6.5m-2-2l2 2" stroke="currentColor"></path></svg></div></div></div><div class="cl dl dk" aria-hidden="true"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Write"><path d="M14 4a.5.5 0 0 0 0-1v1zm7 6a.5.5 0 0 0-1 0h1zm-7-7H4v1h10V3zM3 4v16h1V4H3zm1 17h16v-1H4v1zm17-1V10h-1v10h1zm-1 1a1 1 0 0 0 1-1h-1v1zM3 20a1 1 0 0 0 1 1v-1H3zM4 3a1 1 0 0 0-1 1h1V3z" fill="currentColor"></path><path d="M17.5 4.5l-8.46 8.46a.25.25 0 0 0-.06.1l-.82 2.47c-.07.2.12.38.31.31l2.47-.82a.25.25 0 0 0 .1-.06L19.5 6.5m-2-2l2.32-2.32c.1-.1.26-.1.36 0l1.64 1.64c.1.1.1.26 0 .36L19.5 6.5m-2-2l2 2" stroke="currentColor"></path></svg></div><div class="cl dl bm b dm dn">Write</div></div></div></div></a></span></div><div class="du dv o ao"></div></div></div><div class="ah ai aj ak d"><div class="l ap ar ed as at c"><div class="eb an do ec"><div class="ag o ao ee"><div class="ef dq l eg"></div><div class="ef dq l eg"></div><div class="ef dq l eg"></div></div></div></div></div></nav></div><main class="eh ei ej ek el em l en"><div class="l"><div class="ez l"><div class="o dx"><div class="em ce fa fb fc fd fe ff fg fh fi"><div class="an o ao"><div class="fj l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://towardsdatascience.com/?source=post_page-----3bd2b1164a53--------------------------------" rel="noopener follow"><div class="l do"><img alt="Towards Data Science" class="l ch fl fm fn fp" src="https://miro.medium.com/fit/c/64/64/1*CJe3891yB1A1mzMdqemkdg.jpeg" width="32" height="32" loading="lazy"/><div class="fk fl l fm fn fo aq"></div></div></a></div><div class="fq l fr"><div class="bm b bn bo cn">Published in</div></div><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://towardsdatascience.com/?source=post_page-----3bd2b1164a53--------------------------------" rel="noopener follow"><p class="bm b bn bo fs ft fu fv fw fx fy fz ga">Towards Data Science</p></a></div></div></div></div><div class="gb gc gd ge gf l"><div class="o dx"><div class="em ce fa fb fc fd fe ff fg fh fi"><article><div class="l"><div class="gg gh gi gj gk gl gm ce gn ch l"></div><div class="l"><header class="pw-post-byline-header go gp gq gr gs gt gu gv gw gx l"><div class="o gy u"><div class="o"><div class="fj l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/@_sumitsaha_?source=post_page-----3bd2b1164a53--------------------------------" rel="noopener follow"><div class="l do"><img alt="Sumit Saha" class="l ch fl gz ha fp" src="https://miro.medium.com/fit/c/96/96/1*lYtVkQBgiPiHBemkYIDUwg.jpeg" width="48" height="48" loading="lazy"/><div class="fk fl l gz ha fo aq"></div></div></a></div><div class="l"><div class="pw-author bm b dm dn ga"><div class="hb o hc"><div><div class="ci" aria-hidden="false"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/@_sumitsaha_?source=post_page-----3bd2b1164a53--------------------------------" rel="noopener follow">Sumit Saha</a></div></div><div class="hd he hf hg hh d"><span><a class="bm b hi bo hj hk hl hm hn ho hp bd bz hq hr hs cd cf cg ch ci cj" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F631ee5e6343e&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53&amp;user=Sumit+Saha&amp;userId=631ee5e6343e&amp;source=post_page-631ee5e6343e----3bd2b1164a53---------------------follow_byline-----------" rel="noopener follow">Follow</a></span></div></div></div><div class="o ao ht"><p class="pw-published-date bm b bn bo cn"><span>Dec 15, 2018</span></p><div class="hu ci" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bm b bn bo cn">·</span></span></div><div class="pw-reading-time bm b bn bo cn">7 min read</div></div></div></div><div class="o ao"><div class="h k hv hw hx"><div class="hy l fr"><div><div class="ci" aria-hidden="false"><button class="au av aw ax ay az ba bb bc bd be bf bg bh bi" aria-label="Share on twitter"><span class="ci hz dw ia"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M20 5.34c-.67.41-1.4.7-2.18.87a3.45 3.45 0 0 0-5.02-.1 3.49 3.49 0 0 0-1.02 2.47c0 .28.03.54.07.8a9.91 9.91 0 0 1-7.17-3.66 3.9 3.9 0 0 0-.5 1.74 3.6 3.6 0 0 0 1.56 2.92 3.36 3.36 0 0 1-1.55-.44V10c0 1.67 1.2 3.08 2.8 3.42-.3.06-.6.1-.94.12l-.62-.06a3.5 3.5 0 0 0 3.24 2.43 7.34 7.34 0 0 1-4.36 1.49l-.81-.05a9.96 9.96 0 0 0 5.36 1.56c6.4 0 9.91-5.32 9.9-9.9v-.5c.69-.49 1.28-1.1 1.74-1.81-.63.3-1.3.48-2 .56A3.33 3.33 0 0 0 20 5.33" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="hy l fr"><div><div class="ci" aria-hidden="false"><button class="au av aw ax ay az ba bb bc bd be bf bg bh bi" aria-label="Share on facebook"><span class="ci hz dw ia"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M19.75 12.04c0-4.3-3.47-7.79-7.75-7.79a7.77 7.77 0 0 0-5.9 12.84 7.77 7.77 0 0 0 4.69 2.63v-5.49h-1.9v-2.2h1.9v-1.62c0-1.88 1.14-2.9 2.8-2.9.8 0 1.49.06 1.69.08v1.97h-1.15c-.91 0-1.1.43-1.1 1.07v1.4h2.17l-.28 2.2h-1.88v5.52a7.77 7.77 0 0 0 6.7-7.71" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="hy l fr"><div><div class="ci" aria-hidden="false"><button class="au av aw ax ay az ba bb bc bd be bf bg bh bi" aria-label="Share on linkedin"><span class="ci hz dw ia"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M19.75 5.39v13.22a1.14 1.14 0 0 1-1.14 1.14H5.39a1.14 1.14 0 0 1-1.14-1.14V5.39a1.14 1.14 0 0 1 1.14-1.14h13.22a1.14 1.14 0 0 1 1.14 1.14zM8.81 10.18H6.53v7.3H8.8v-7.3zM9 7.67a1.31 1.31 0 0 0-1.3-1.32h-.04a1.32 1.32 0 0 0 0 2.64A1.31 1.31 0 0 0 9 7.71v-.04zm8.46 5.37c0-2.2-1.4-3.05-2.78-3.05a2.6 2.6 0 0 0-2.3 1.18h-.07v-1h-2.14v7.3h2.28V13.6a1.51 1.51 0 0 1 1.36-1.63h.09c.72 0 1.26.45 1.26 1.6v3.91h2.28l.02-4.43z" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="l fr"><div><div class="ci" aria-hidden="false"><button class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci hz dw ia"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M3.57 14.67c0-.57.13-1.11.38-1.6l.02-.02v-.02l.02-.02c0-.02 0-.02.02-.02.12-.26.3-.52.57-.8L7.78 9v-.02l.01-.02c.44-.41.91-.7 1.44-.85a4.87 4.87 0 0 0-1.19 2.36A5.04 5.04 0 0 0 8 11.6L6.04 13.6c-.19.19-.32.4-.38.65a2 2 0 0 0 0 .9c.08.2.2.4.38.57l1.29 1.31c.27.28.62.42 1.03.42.42 0 .78-.14 1.06-.42l1.23-1.25.79-.78 1.15-1.16c.08-.09.19-.22.28-.4.1-.2.15-.42.15-.67 0-.16-.02-.3-.06-.45l-.02-.02v-.02l-.07-.14s0-.03-.04-.06l-.06-.13-.02-.02c0-.02 0-.03-.02-.05a.6.6 0 0 0-.14-.16l-.48-.5c0-.04.02-.1.04-.15l.06-.12 1.17-1.14.09-.09.56.57c.02.04.08.1.16.18l.05.04.03.06.04.05.03.04.04.06.1.14.02.02c0 .02.01.03.03.04l.1.2v.02c.1.16.2.38.3.68a1 1 0 0 1 .04.25 3.2 3.2 0 0 1 .02 1.33 3.49 3.49 0 0 1-.95 1.87l-.66.67-.97.97-1.56 1.57a3.4 3.4 0 0 1-2.47 1.02c-.97 0-1.8-.34-2.49-1.03l-1.3-1.3a3.55 3.55 0 0 1-1-2.51v-.01h-.02v.02zm5.39-3.43c0-.19.02-.4.07-.63.13-.74.44-1.37.95-1.87l.66-.67.97-.98 1.56-1.56c.68-.69 1.5-1.03 2.47-1.03.97 0 1.8.34 2.48 1.02l1.3 1.32a3.48 3.48 0 0 1 1 2.48c0 .58-.11 1.11-.37 1.6l-.02.02v.02l-.02.04c-.14.27-.35.54-.6.8L16.23 15l-.01.02-.01.02c-.44.42-.92.7-1.43.83a4.55 4.55 0 0 0 1.23-3.52L18 10.38c.18-.21.3-.42.35-.65a2.03 2.03 0 0 0-.01-.9 1.96 1.96 0 0 0-.36-.58l-1.3-1.3a1.49 1.49 0 0 0-1.06-.42c-.42 0-.77.14-1.06.4l-1.2 1.27-.8.8-1.16 1.15c-.08.08-.18.21-.29.4a1.66 1.66 0 0 0-.08 1.12l.02.03v.02l.06.14s.01.03.05.06l.06.13.02.02.01.02.01.02c.05.08.1.13.14.16l.47.5c0 .04-.02.09-.04.15l-.06.12-1.15 1.15-.1.08-.56-.56a2.3 2.3 0 0 0-.18-.19c-.02-.01-.02-.03-.02-.04l-.02-.02a.37.37 0 0 1-.1-.12c-.03-.03-.05-.04-.05-.06l-.1-.15-.02-.02-.02-.04-.08-.17v-.02a5.1 5.1 0 0 1-.28-.69 1.03 1.03 0 0 1-.04-.26c-.06-.23-.1-.46-.1-.7v.01z" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="ib o ao"></div></div><div class="ck ic"><div><div class="ci" aria-hidden="false"></div></div></div></div></div><div class="id ie if j i d"><div class="fj l"></div><div class="ig l fr"><div><div class="ci" aria-hidden="false"><button class="au av aw ax ay az ba bb bc bd be bf bg bh bi" aria-label="Share on twitter"><span class="ci hz dw ia"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M20 5.34c-.67.41-1.4.7-2.18.87a3.45 3.45 0 0 0-5.02-.1 3.49 3.49 0 0 0-1.02 2.47c0 .28.03.54.07.8a9.91 9.91 0 0 1-7.17-3.66 3.9 3.9 0 0 0-.5 1.74 3.6 3.6 0 0 0 1.56 2.92 3.36 3.36 0 0 1-1.55-.44V10c0 1.67 1.2 3.08 2.8 3.42-.3.06-.6.1-.94.12l-.62-.06a3.5 3.5 0 0 0 3.24 2.43 7.34 7.34 0 0 1-4.36 1.49l-.81-.05a9.96 9.96 0 0 0 5.36 1.56c6.4 0 9.91-5.32 9.9-9.9v-.5c.69-.49 1.28-1.1 1.74-1.81-.63.3-1.3.48-2 .56A3.33 3.33 0 0 0 20 5.33" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="ig l fr"><div><div class="ci" aria-hidden="false"><button class="au av aw ax ay az ba bb bc bd be bf bg bh bi" aria-label="Share on facebook"><span class="ci hz dw ia"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M19.75 12.04c0-4.3-3.47-7.79-7.75-7.79a7.77 7.77 0 0 0-5.9 12.84 7.77 7.77 0 0 0 4.69 2.63v-5.49h-1.9v-2.2h1.9v-1.62c0-1.88 1.14-2.9 2.8-2.9.8 0 1.49.06 1.69.08v1.97h-1.15c-.91 0-1.1.43-1.1 1.07v1.4h2.17l-.28 2.2h-1.88v5.52a7.77 7.77 0 0 0 6.7-7.71" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="ig l fr"><div><div class="ci" aria-hidden="false"><button class="au av aw ax ay az ba bb bc bd be bf bg bh bi" aria-label="Share on linkedin"><span class="ci hz dw ia"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M19.75 5.39v13.22a1.14 1.14 0 0 1-1.14 1.14H5.39a1.14 1.14 0 0 1-1.14-1.14V5.39a1.14 1.14 0 0 1 1.14-1.14h13.22a1.14 1.14 0 0 1 1.14 1.14zM8.81 10.18H6.53v7.3H8.8v-7.3zM9 7.67a1.31 1.31 0 0 0-1.3-1.32h-.04a1.32 1.32 0 0 0 0 2.64A1.31 1.31 0 0 0 9 7.71v-.04zm8.46 5.37c0-2.2-1.4-3.05-2.78-3.05a2.6 2.6 0 0 0-2.3 1.18h-.07v-1h-2.14v7.3h2.28V13.6a1.51 1.51 0 0 1 1.36-1.63h.09c.72 0 1.26.45 1.26 1.6v3.91h2.28l.02-4.43z" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="l fr"><div><div class="ci" aria-hidden="false"><button class="au av aw ax ay az ba bb bc bd be bf bg bh bi"><span class="ci hz dw ia"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M3.57 14.67c0-.57.13-1.11.38-1.6l.02-.02v-.02l.02-.02c0-.02 0-.02.02-.02.12-.26.3-.52.57-.8L7.78 9v-.02l.01-.02c.44-.41.91-.7 1.44-.85a4.87 4.87 0 0 0-1.19 2.36A5.04 5.04 0 0 0 8 11.6L6.04 13.6c-.19.19-.32.4-.38.65a2 2 0 0 0 0 .9c.08.2.2.4.38.57l1.29 1.31c.27.28.62.42 1.03.42.42 0 .78-.14 1.06-.42l1.23-1.25.79-.78 1.15-1.16c.08-.09.19-.22.28-.4.1-.2.15-.42.15-.67 0-.16-.02-.3-.06-.45l-.02-.02v-.02l-.07-.14s0-.03-.04-.06l-.06-.13-.02-.02c0-.02 0-.03-.02-.05a.6.6 0 0 0-.14-.16l-.48-.5c0-.04.02-.1.04-.15l.06-.12 1.17-1.14.09-.09.56.57c.02.04.08.1.16.18l.05.04.03.06.04.05.03.04.04.06.1.14.02.02c0 .02.01.03.03.04l.1.2v.02c.1.16.2.38.3.68a1 1 0 0 1 .04.25 3.2 3.2 0 0 1 .02 1.33 3.49 3.49 0 0 1-.95 1.87l-.66.67-.97.97-1.56 1.57a3.4 3.4 0 0 1-2.47 1.02c-.97 0-1.8-.34-2.49-1.03l-1.3-1.3a3.55 3.55 0 0 1-1-2.51v-.01h-.02v.02zm5.39-3.43c0-.19.02-.4.07-.63.13-.74.44-1.37.95-1.87l.66-.67.97-.98 1.56-1.56c.68-.69 1.5-1.03 2.47-1.03.97 0 1.8.34 2.48 1.02l1.3 1.32a3.48 3.48 0 0 1 1 2.48c0 .58-.11 1.11-.37 1.6l-.02.02v.02l-.02.04c-.14.27-.35.54-.6.8L16.23 15l-.01.02-.01.02c-.44.42-.92.7-1.43.83a4.55 4.55 0 0 0 1.23-3.52L18 10.38c.18-.21.3-.42.35-.65a2.03 2.03 0 0 0-.01-.9 1.96 1.96 0 0 0-.36-.58l-1.3-1.3a1.49 1.49 0 0 0-1.06-.42c-.42 0-.77.14-1.06.4l-1.2 1.27-.8.8-1.16 1.15c-.08.08-.18.21-.29.4a1.66 1.66 0 0 0-.08 1.12l.02.03v.02l.06.14s.01.03.05.06l.06.13.02.02.01.02.01.02c.05.08.1.13.14.16l.47.5c0 .04-.02.09-.04.15l-.06.12-1.15 1.15-.1.08-.56-.56a2.3 2.3 0 0 0-.18-.19c-.02-.01-.02-.03-.02-.04l-.02-.02a.37.37 0 0 1-.1-.12c-.03-.03-.05-.04-.05-.06l-.1-.15-.02-.02-.02-.04-.08-.17v-.02a5.1 5.1 0 0 1-.28-.69 1.03 1.03 0 0 1-.04-.26c-.06-.23-.1-.46-.1-.7v.01z" fill="#A8A8A8"></path></svg></span></button></div></div></div></div></header><span class="l"></span><section><div><div class="fo as in io ip iq"></div><div class="ir is it iu iv"><div class=""><h1 id="2a13" class="pw-post-title iw ix iy bm iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju ga">A Comprehensive Guide to Convolutional Neural Networks — the ELI5 way</h1></div><figure class="gp gr jw jx jy jz gl gm paragraph-image"><div role="button" tabindex="0" class="ka kb do kc ce kd"><div class="gl gm jv"><picture><source data-testid="og" srcSet="https://miro.medium.com/max/640/1*vkQ0hXDaQv57sALXAJquxA.jpeg 640w, https://miro.medium.com/max/720/1*vkQ0hXDaQv57sALXAJquxA.jpeg 720w, https://miro.medium.com/max/750/1*vkQ0hXDaQv57sALXAJquxA.jpeg 750w, https://miro.medium.com/max/786/1*vkQ0hXDaQv57sALXAJquxA.jpeg 786w, https://miro.medium.com/max/828/1*vkQ0hXDaQv57sALXAJquxA.jpeg 828w, https://miro.medium.com/max/1100/1*vkQ0hXDaQv57sALXAJquxA.jpeg 1100w, https://miro.medium.com/max/1400/1*vkQ0hXDaQv57sALXAJquxA.jpeg 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="ce ke kf c" width="700" height="237" loading="eager" role="presentation"/></picture></div></div></figure><p id="0bac" class="pw-post-body-paragraph kg kh iy ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ir ga">Artificial Intelligence has been witnessing a monumental growth in bridging the gap between the capabilities of humans and machines. Researchers and enthusiasts alike, work on numerous aspects of the field to make amazing things happen. One of many such areas is the domain of Computer Vision.</p><p id="7431" class="pw-post-body-paragraph kg kh iy ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ir ga">The agenda for this field is to enable machines to view the world as humans do, perceive it in a similar manner and even use the knowledge for a multitude of tasks such as Image &amp; Video recognition, Image Analysis &amp; Classification, Media Recreation, Recommendation Systems, Natural Language Processing, etc. The advancements in Computer Vision with Deep Learning has been constructed and perfected with time, primarily over one particular algorithm — a <strong class="ki iz">Convolutional Neural Network</strong>.</p><h2 id="a61f" class="le lf iy bm lg lh li lj lk ll lm ln lo kr lp lq lr kv ls lt lu kz lv lw lx ly ga">Introduction</h2><figure class="ma mb mc md gx jz gl gm paragraph-image"><div role="button" tabindex="0" class="ka kb do kc ce kd"><div class="gl gm lz"><picture><source data-testid="og" srcSet="https://miro.medium.com/max/640/1*uAeANQIOQPqWZnnuH-VEyw.jpeg 640w, https://miro.medium.com/max/720/1*uAeANQIOQPqWZnnuH-VEyw.jpeg 720w, https://miro.medium.com/max/750/1*uAeANQIOQPqWZnnuH-VEyw.jpeg 750w, https://miro.medium.com/max/786/1*uAeANQIOQPqWZnnuH-VEyw.jpeg 786w, https://miro.medium.com/max/828/1*uAeANQIOQPqWZnnuH-VEyw.jpeg 828w, https://miro.medium.com/max/1100/1*uAeANQIOQPqWZnnuH-VEyw.jpeg 1100w, https://miro.medium.com/max/1400/1*uAeANQIOQPqWZnnuH-VEyw.jpeg 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="ce ke kf c" width="700" height="375" loading="lazy" role="presentation"/></picture></div></div><figcaption class="me bl gn gl gm mf mg bm b bn bo cn">A CNN sequence to classify handwritten digits</figcaption></figure><p id="fb70" class="pw-post-body-paragraph kg kh iy ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ir ga">A <strong class="ki iz">Convolutional Neural Network (ConvNet/CNN)</strong> is a Deep Learning algorithm which can take in an input image, assign importance (learnable weights and biases) to various aspects/objects in the image and be able to differentiate one from the other. The pre-processing required in a ConvNet is much lower as compared to other classification algorithms. While in primitive methods filters are hand-engineered, with enough training, ConvNets have the ability to learn these filters/characteristics.</p><p id="ffef" class="pw-post-body-paragraph kg kh iy ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ir ga">The architecture of a ConvNet is analogous to that of the connectivity pattern of Neurons in the Human Brain and was inspired by the organization of the Visual Cortex. Individual neurons respond to stimuli only in a restricted region of the visual field known as the Receptive Field. A collection of such fields overlap to cover the entire visual area.</p><h2 id="9dc9" class="le lf iy bm lg lh li lj lk ll lm ln lo kr lp lq lr kv ls lt lu kz lv lw lx ly ga">Why ConvNets over Feed-Forward Neural Nets?</h2><figure class="ma mb mc md gx jz gl gm paragraph-image"><div class="gl gm mh"><picture><source data-testid="og" srcSet="https://miro.medium.com/max/640/1*GLQjM9k0gZ14nYF0XmkRWQ.png 640w, https://miro.medium.com/max/720/1*GLQjM9k0gZ14nYF0XmkRWQ.png 720w, https://miro.medium.com/max/750/1*GLQjM9k0gZ14nYF0XmkRWQ.png 750w, https://miro.medium.com/max/786/1*GLQjM9k0gZ14nYF0XmkRWQ.png 786w, https://miro.medium.com/max/828/1*GLQjM9k0gZ14nYF0XmkRWQ.png 828w, https://miro.medium.com/max/1100/1*GLQjM9k0gZ14nYF0XmkRWQ.png 1100w, https://miro.medium.com/max/850/1*GLQjM9k0gZ14nYF0XmkRWQ.png 850w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 425px"/><img alt="" class="ce ke kf c" width="425" height="351" loading="lazy" role="presentation"/></picture></div><figcaption class="me bl gn gl gm mf mg bm b bn bo cn">Flattening of a 3x3 image matrix into a 9x1 vector</figcaption></figure><p id="6383" class="pw-post-body-paragraph kg kh iy ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ir ga">An image is nothing but a matrix of pixel values, right? So why not just flatten the image (e.g. 3x3 image matrix into a 9x1 vector) and feed it to a Multi-Level Perceptron for classification purposes? Uh.. not really.</p><p id="df65" class="pw-post-body-paragraph kg kh iy ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ir ga">In cases of extremely basic binary images, the method might show an average precision score while performing prediction of classes but would have little to no accuracy when it comes to complex images having pixel dependencies throughout.</p><p id="4f1c" class="pw-post-body-paragraph kg kh iy ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ir ga">A ConvNet is able to <strong class="ki iz">successfully capture the Spatial and Temporal dependencies</strong> in an image through the application of relevant filters. The architecture performs a better fitting to the image dataset due to the reduction in the number of parameters involved and reusability of weights. In other words, the network can be trained to understand the sophistication of the image better.</p><h2 id="c380" class="le lf iy bm lg lh li lj lk ll lm ln lo kr lp lq lr kv ls lt lu kz lv lw lx ly ga">Input Image</h2><figure class="ma mb mc md gx jz gl gm paragraph-image"><div class="gl gm mi"><picture><source data-testid="og" srcSet="https://miro.medium.com/max/640/1*15yDvGKV47a0nkf5qLKOOQ.png 640w, https://miro.medium.com/max/720/1*15yDvGKV47a0nkf5qLKOOQ.png 720w, https://miro.medium.com/max/750/1*15yDvGKV47a0nkf5qLKOOQ.png 750w, https://miro.medium.com/max/786/1*15yDvGKV47a0nkf5qLKOOQ.png 786w, https://miro.medium.com/max/828/1*15yDvGKV47a0nkf5qLKOOQ.png 828w, https://miro.medium.com/max/1100/1*15yDvGKV47a0nkf5qLKOOQ.png 1100w, https://miro.medium.com/max/1100/1*15yDvGKV47a0nkf5qLKOOQ.png 1100w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 550px"/><img alt="" class="ce ke kf c" width="550" height="400" loading="lazy" role="presentation"/></picture></div><figcaption class="me bl gn gl gm mf mg bm b bn bo cn">4x4x3 RGB Image</figcaption></figure><p id="f21b" class="pw-post-body-paragraph kg kh iy ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ir ga">In the figure, we have an RGB image which has been separated by its three color planes — Red, Green, and Blue. There are a number of such color spaces in which images exist — Grayscale, RGB, HSV, CMYK, etc.</p><p id="3bb1" class="pw-post-body-paragraph kg kh iy ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ir ga">You can imagine how computationally intensive things would get once the images reach dimensions, say 8K (7680×4320). The role of the ConvNet is to reduce the images into a form which is easier to process, without losing features which are critical for getting a good prediction. This is important when we are to design an architecture which is not only good at learning features but also is scalable to massive datasets.</p><h2 id="cad1" class="le lf iy bm lg lh li lj lk ll lm ln lo kr lp lq lr kv ls lt lu kz lv lw lx ly ga">Convolution Layer — The Kernel</h2><figure class="ma mb mc md gx jz gl gm paragraph-image"><div class="gl gm mj"><picture><source data-testid="og" srcSet="https://miro.medium.com/max/640/1*GcI7G-JLAQiEoCON7xFbhg.gif 640w, https://miro.medium.com/max/720/1*GcI7G-JLAQiEoCON7xFbhg.gif 720w, https://miro.medium.com/max/750/1*GcI7G-JLAQiEoCON7xFbhg.gif 750w, https://miro.medium.com/max/786/1*GcI7G-JLAQiEoCON7xFbhg.gif 786w, https://miro.medium.com/max/828/1*GcI7G-JLAQiEoCON7xFbhg.gif 828w, https://miro.medium.com/max/1100/1*GcI7G-JLAQiEoCON7xFbhg.gif 1100w, https://miro.medium.com/max/1052/1*GcI7G-JLAQiEoCON7xFbhg.gif 1052w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 526px"/><img alt="" class="ce ke kf c" width="526" height="384" loading="lazy" role="presentation"/></picture></div><figcaption class="me bl gn gl gm mf mg bm b bn bo cn">Convoluting a 5x5x1 image with a 3x3x1 kernel to get a 3x3x1 convolved feature</figcaption></figure><p id="0f71" class="pw-post-body-paragraph kg kh iy ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ir ga">Image Dimensions = 5 (Height) x 5 (Breadth) x 1 (Number of channels, eg. RGB)</p><p id="9be0" class="pw-post-body-paragraph kg kh iy ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ir ga">In the above demonstration, the green section resembles our <strong class="ki iz">5x5x1 input image, I</strong>. The element involved in carrying out the convolution operation in the first part of a Convolutional Layer is called the <strong class="ki iz">Kernel/Filter, K</strong>, represented in the color yellow. We have selected <strong class="ki iz">K as a 3x3x1 matrix.</strong></p><pre class="ma mb mc md gx mk bs ml mm dz mn"><span id="e9b7" class="ga le lf iy mn b dm mo mp l mq mr">Kernel/Filter, K = </span><span id="63d3" class="ga le lf iy mn b dm ms mp l mq mr">1  0  1<br/>0  1  0<br/>1  0  1</span></pre><p id="b923" class="pw-post-body-paragraph kg kh iy ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ir ga">The Kernel shifts 9 times because of <strong class="ki iz">Stride Length = 1 (Non-Strided)</strong>, every time performing a <strong class="ki iz">matrix multiplication operation between K and the portion P of the image</strong> over which the kernel is hovering.</p><figure class="ma mb mc md gx jz gl gm paragraph-image"><div class="gl gm mt"><picture><source data-testid="og" srcSet="https://miro.medium.com/max/640/1*NsiYxt8tPDQyjyH3C08PVA@2x.png 640w, https://miro.medium.com/max/720/1*NsiYxt8tPDQyjyH3C08PVA@2x.png 720w, https://miro.medium.com/max/750/1*NsiYxt8tPDQyjyH3C08PVA@2x.png 750w, https://miro.medium.com/max/786/1*NsiYxt8tPDQyjyH3C08PVA@2x.png 786w, https://miro.medium.com/max/828/1*NsiYxt8tPDQyjyH3C08PVA@2x.png 828w, https://miro.medium.com/max/1100/1*NsiYxt8tPDQyjyH3C08PVA@2x.png 1100w, https://miro.medium.com/max/652/1*NsiYxt8tPDQyjyH3C08PVA@2x.png 652w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 326px"/><img alt="" class="ce ke kf c" width="326" height="463" loading="lazy" role="presentation"/></picture></div><figcaption class="me bl gn gl gm mf mg bm b bn bo cn">Movement of the Kernel</figcaption></figure><p id="e26f" class="pw-post-body-paragraph kg kh iy ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ir ga">The filter moves to the right with a certain Stride Value till it parses the complete width. Moving on, it hops down to the beginning (left) of the image with the same Stride Value and repeats the process until the entire image is traversed.</p><figure class="ma mb mc md gx jz gl gm paragraph-image"><div role="button" tabindex="0" class="ka kb do kc ce kd"><div class="gl gm mu"><picture><source data-testid="og" srcSet="https://miro.medium.com/max/640/1*ciDgQEjViWLnCbmX-EeSrA.gif 640w, https://miro.medium.com/max/720/1*ciDgQEjViWLnCbmX-EeSrA.gif 720w, https://miro.medium.com/max/750/1*ciDgQEjViWLnCbmX-EeSrA.gif 750w, https://miro.medium.com/max/786/1*ciDgQEjViWLnCbmX-EeSrA.gif 786w, https://miro.medium.com/max/828/1*ciDgQEjViWLnCbmX-EeSrA.gif 828w, https://miro.medium.com/max/1100/1*ciDgQEjViWLnCbmX-EeSrA.gif 1100w, https://miro.medium.com/max/1400/1*ciDgQEjViWLnCbmX-EeSrA.gif 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="ce ke kf c" width="700" height="394" loading="lazy" role="presentation"/></picture></div></div><figcaption class="me bl gn gl gm mf mg bm b bn bo cn">Convolution operation on a MxNx3 image matrix with a 3x3x3 Kernel</figcaption></figure><p id="54cb" class="pw-post-body-paragraph kg kh iy ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ir ga">In the case of images with multiple channels (e.g. RGB), the Kernel has the same depth as that of the input image. Matrix Multiplication is performed between Kn and In stack ([K1, I1]; [K2, I2]; [K3, I3]) and all the results are summed with the bias to give us a squashed one-depth channel Convoluted Feature Output.</p><figure class="ma mb mc md gx jz gl gm paragraph-image"><div class="gl gm mv"><picture><source data-testid="og" srcSet="https://miro.medium.com/max/640/1*1VJDP6qDY9-ExTuQVEOlVg.gif 640w, https://miro.medium.com/max/720/1*1VJDP6qDY9-ExTuQVEOlVg.gif 720w, https://miro.medium.com/max/750/1*1VJDP6qDY9-ExTuQVEOlVg.gif 750w, https://miro.medium.com/max/786/1*1VJDP6qDY9-ExTuQVEOlVg.gif 786w, https://miro.medium.com/max/828/1*1VJDP6qDY9-ExTuQVEOlVg.gif 828w, https://miro.medium.com/max/1100/1*1VJDP6qDY9-ExTuQVEOlVg.gif 1100w, https://miro.medium.com/max/790/1*1VJDP6qDY9-ExTuQVEOlVg.gif 790w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 395px"/><img alt="" class="ce ke kf c" width="395" height="381" loading="lazy" role="presentation"/></picture></div><figcaption class="me bl gn gl gm mf mg bm b bn bo cn">Convolution Operation with Stride Length = 2</figcaption></figure><p id="a57a" class="pw-post-body-paragraph kg kh iy ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ir ga">The objective of the Convolution Operation is to <strong class="ki iz">extract the high-level features</strong> such as edges, from the input image. ConvNets need not be limited to only one Convolutional Layer. Conventionally, the first ConvLayer is responsible for capturing the Low-Level features such as edges, color, gradient orientation, etc. With added layers, the architecture adapts to the High-Level features as well, giving us a network which has the wholesome understanding of images in the dataset, similar to how we would.</p><p id="7f9d" class="pw-post-body-paragraph kg kh iy ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ir ga">There are two types of results to the operation — one in which the convolved feature is reduced in dimensionality as compared to the input, and the other in which the dimensionality is either increased or remains the same. This is done by applying <strong class="ki iz">Valid Padding</strong> in case of the former, or <strong class="ki iz">Same Padding</strong> in the case of the latter.</p><figure class="ma mb mc md gx jz gl gm paragraph-image"><div class="gl gm mv"><picture><source data-testid="og" srcSet="https://miro.medium.com/max/640/1*nYf_cUIHFEWU1JXGwnz-Ig.gif 640w, https://miro.medium.com/max/720/1*nYf_cUIHFEWU1JXGwnz-Ig.gif 720w, https://miro.medium.com/max/750/1*nYf_cUIHFEWU1JXGwnz-Ig.gif 750w, https://miro.medium.com/max/786/1*nYf_cUIHFEWU1JXGwnz-Ig.gif 786w, https://miro.medium.com/max/828/1*nYf_cUIHFEWU1JXGwnz-Ig.gif 828w, https://miro.medium.com/max/1100/1*nYf_cUIHFEWU1JXGwnz-Ig.gif 1100w, https://miro.medium.com/max/790/1*nYf_cUIHFEWU1JXGwnz-Ig.gif 790w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 395px"/><img alt="" class="ce ke kf c" width="395" height="449" loading="lazy" role="presentation"/></picture></div><figcaption class="me bl gn gl gm mf mg bm b bn bo cn"><strong class="bm mw">SAME padding:</strong> 5x5x1 image is padded with 0s to create a 6x6x1 image</figcaption></figure><p id="8652" class="pw-post-body-paragraph kg kh iy ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ir ga">When we augment the 5x5x1 image into a 6x6x1 image and then apply the 3x3x1 kernel over it, we find that the convolved matrix turns out to be of dimensions 5x5x1. Hence the name — <strong class="ki iz">Same Padding</strong>.</p><p id="7bb2" class="pw-post-body-paragraph kg kh iy ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ir ga">On the other hand, if we perform the same operation without padding, we are presented with a matrix which has dimensions of the Kernel (3x3x1) itself — <strong class="ki iz">Valid Padding</strong>.</p><p id="8d12" class="pw-post-body-paragraph kg kh iy ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ir ga">The following repository houses many such GIFs which would help you get a better understanding of how Padding and Stride Length work together to achieve results relevant to our needs.</p><div class="mx my gt gv mz na"><a href="https://github.com/vdumoulin/conv_arithmetic" rel="noopener  ugc nofollow" target="_blank"><div class="nb o fr"><div class="nc o da dx en nd"><h2 class="bm iz dm bo fs ne fu fv nf fx fz ix ga">vdumoulin/conv_arithmetic</h2><div class="ng l"><h3 class="bm b dm bo fs ne fu fv nf fx fz cn">A technical report on convolution arithmetic in the context of deep learning - vdumoulin/conv_arithmetic</h3></div><div class="nh l"><p class="bm b hi bo fs ne fu fv nf fx fz cn">github.com</p></div></div><div class="ni l"><div class="nj l nk nl nm ni nn ke na"></div></div></div></a></div><h2 id="333b" class="le lf iy bm lg lh li lj lk ll lm ln lo kr lp lq lr kv ls lt lu kz lv lw lx ly ga">Pooling Layer</h2><figure class="ma mb mc md gx jz gl gm paragraph-image"><div class="gl gm no"><picture><source data-testid="og" srcSet="https://miro.medium.com/max/640/1*uoWYsCV5vBU8SHFPAPao-w.gif 640w, https://miro.medium.com/max/720/1*uoWYsCV5vBU8SHFPAPao-w.gif 720w, https://miro.medium.com/max/750/1*uoWYsCV5vBU8SHFPAPao-w.gif 750w, https://miro.medium.com/max/786/1*uoWYsCV5vBU8SHFPAPao-w.gif 786w, https://miro.medium.com/max/828/1*uoWYsCV5vBU8SHFPAPao-w.gif 828w, https://miro.medium.com/max/1100/1*uoWYsCV5vBU8SHFPAPao-w.gif 1100w, https://miro.medium.com/max/792/1*uoWYsCV5vBU8SHFPAPao-w.gif 792w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 396px"/><img alt="" class="ce ke kf c" width="396" height="248" loading="lazy" role="presentation"/></picture></div><figcaption class="me bl gn gl gm mf mg bm b bn bo cn">3x3 pooling over 5x5 convolved feature</figcaption></figure><p id="6015" class="pw-post-body-paragraph kg kh iy ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ir ga">Similar to the Convolutional Layer, the Pooling layer is responsible for reducing the spatial size of the Convolved Feature. This is to <strong class="ki iz">decrease the computational power required to process the data</strong> through dimensionality reduction. Furthermore, it is useful for <strong class="ki iz">extracting dominant features</strong> which are rotational and positional invariant, thus maintaining the process of effectively training of the model.</p><p id="6ee5" class="pw-post-body-paragraph kg kh iy ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ir ga">There are two types of Pooling: Max Pooling and Average Pooling. <strong class="ki iz">Max Pooling</strong> returns the <strong class="ki iz">maximum value</strong> from the portion of the image covered by the Kernel. On the other hand, <strong class="ki iz">Average Pooling </strong>returns the <strong class="ki iz">average of all the values </strong>from the portion of the image covered by the Kernel.</p><p id="b9da" class="pw-post-body-paragraph kg kh iy ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ir ga">Max Pooling also performs as a<strong class="ki iz"> Noise Suppressant</strong>. It discards the noisy activations altogether and also performs de-noising along with dimensionality reduction. On the other hand, Average Pooling simply performs dimensionality reduction as a noise suppressing mechanism. Hence, we can say that <strong class="ki iz">Max Pooling performs a lot better than Average Pooling</strong>.</p><figure class="ma mb mc md gx jz gl gm paragraph-image"><div class="gl gm np"><picture><source data-testid="og" srcSet="https://miro.medium.com/max/640/1*KQIEqhxzICU7thjaQBfPBQ.png 640w, https://miro.medium.com/max/720/1*KQIEqhxzICU7thjaQBfPBQ.png 720w, https://miro.medium.com/max/750/1*KQIEqhxzICU7thjaQBfPBQ.png 750w, https://miro.medium.com/max/786/1*KQIEqhxzICU7thjaQBfPBQ.png 786w, https://miro.medium.com/max/828/1*KQIEqhxzICU7thjaQBfPBQ.png 828w, https://miro.medium.com/max/1100/1*KQIEqhxzICU7thjaQBfPBQ.png 1100w, https://miro.medium.com/max/1192/1*KQIEqhxzICU7thjaQBfPBQ.png 1192w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 596px"/><img alt="" class="ce ke kf c" width="596" height="439" loading="lazy" role="presentation"/></picture></div><figcaption class="me bl gn gl gm mf mg bm b bn bo cn">Types of Pooling</figcaption></figure><p id="6915" class="pw-post-body-paragraph kg kh iy ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ir ga">The Convolutional Layer and the Pooling Layer, together form the i-th layer of a Convolutional Neural Network. Depending on the complexities in the images, the number of such layers may be increased for capturing low-levels details even further, but at the cost of more computational power.</p><p id="3751" class="pw-post-body-paragraph kg kh iy ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ir ga">After going through the above process, we have successfully enabled the model to understand the features. Moving on, we are going to flatten the final output and feed it to a regular Neural Network for classification purposes.</p><h2 id="82e5" class="le lf iy bm lg lh li lj lk ll lm ln lo kr lp lq lr kv ls lt lu kz lv lw lx ly ga">Classification — Fully Connected Layer (FC Layer)</h2><figure class="ma mb mc md gx jz gl gm paragraph-image"><div role="button" tabindex="0" class="ka kb do kc ce kd"><div class="gl gm nq"><picture><source data-testid="og" srcSet="https://miro.medium.com/max/640/1*kToStLowjokojIQ7pY2ynQ.jpeg 640w, https://miro.medium.com/max/720/1*kToStLowjokojIQ7pY2ynQ.jpeg 720w, https://miro.medium.com/max/750/1*kToStLowjokojIQ7pY2ynQ.jpeg 750w, https://miro.medium.com/max/786/1*kToStLowjokojIQ7pY2ynQ.jpeg 786w, https://miro.medium.com/max/828/1*kToStLowjokojIQ7pY2ynQ.jpeg 828w, https://miro.medium.com/max/1100/1*kToStLowjokojIQ7pY2ynQ.jpeg 1100w, https://miro.medium.com/max/1400/1*kToStLowjokojIQ7pY2ynQ.jpeg 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="ce ke kf c" width="700" height="408" loading="lazy" role="presentation"/></picture></div></div></figure><p id="7432" class="pw-post-body-paragraph kg kh iy ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ir ga">Adding a Fully-Connected layer is a (usually) cheap way of learning non-linear combinations of the high-level features as represented by the output of the convolutional layer. The Fully-Connected layer is learning a possibly non-linear function in that space.</p><p id="2f60" class="pw-post-body-paragraph kg kh iy ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ir ga">Now that we have converted our input image into a suitable form for our Multi-Level Perceptron, we shall flatten the image into a column vector. The flattened output is fed to a feed-forward neural network and backpropagation applied to every iteration of training. Over a series of epochs, the model is able to distinguish between dominating and certain low-level features in images and classify them using the <strong class="ki iz">Softmax Classification</strong> technique.</p><p id="53a6" class="pw-post-body-paragraph kg kh iy ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ir ga">There are various architectures of CNNs available which have been key in building algorithms which power and shall power AI as a whole in the foreseeable future. Some of them have been listed below:</p><ol class=""><li id="b784" class="nr ns iy ki b kj kk kn ko kr nt kv nu kz nv ld nw nx ny nz ga">LeNet</li><li id="2ba9" class="nr ns iy ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz ga">AlexNet</li><li id="3f07" class="nr ns iy ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz ga">VGGNet</li><li id="e514" class="nr ns iy ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz ga">GoogLeNet</li><li id="735c" class="nr ns iy ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz ga">ResNet</li><li id="b68a" class="nr ns iy ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz ga">ZFNet</li></ol></div><div class="o dx of og id oh" role="separator"><span class="oi fl ci oj ok ol"></span><span class="oi fl ci oj ok ol"></span><span class="oi fl ci oj ok"></span></div><div class="ir is it iu iv"><p id="9c7d" class="pw-post-body-paragraph kg kh iy ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld ir ga"><strong class="ki iz">GitHub Notebook — Recognising Hand Written Digits using MNIST Dataset with TensorFlow</strong></p><div class="mx my gt gv mz na"><a href="https://github.com/ss-is-master-chief/MNIST-Digit.Recognizer-CNNs" rel="noopener  ugc nofollow" target="_blank"><div class="nb o fr"><div class="nc o da dx en nd"><h2 class="bm iz dm bo fs ne fu fv nf fx fz ix ga">ss-is-master-chief/MNIST-Digit.Recognizer-CNNs</h2><div class="ng l"><h3 class="bm b dm bo fs ne fu fv nf fx fz cn">Implementation of CNN to recognize hand written digits (MNIST) running for 10 epochs. Accuracy: 98.99% …</h3></div><div class="nh l"><p class="bm b hi bo fs ne fu fv nf fx fz cn">github.com</p></div></div><div class="ni l"><div class="om l nk nl nm ni nn ke na"></div></div></div></a></div></div></div></section></div></div></article><div class="on o"></div></div></div><div class="l"></div><footer class="oo op oq or o ao os ot c"><div class="l ou"><div class="o dx"><div class="em ce fa fb fc fd fe ff fg fh fi"><div class="o u ov"><div class="o ao hc"><div class="ow l"><span class="l he ox oy e d"><div class="o ao hc"><div class="pw-multi-vote-icon do oz pa pb pc"><div class=""><div class="dr pd de pe pf pg ph bb pi pj pk pc"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM15.42 1.84l-1.18-.39-.34 2.5 1.52-2.1zM9.76 1.45l-1.19.4 1.53 2.1-.34-2.5zM20.25 11.84l-2.5-4.4a1.42 1.42 0 0 0-.93-.64.96.96 0 0 0-.75.18c-.25.19-.4.42-.45.7l.05.05 2.35 4.13c1.62 2.95 1.1 5.78-1.52 8.4l-.46.41c1-.13 1.93-.6 2.78-1.45 2.7-2.7 2.51-5.59 1.43-7.38zM12.07 9.01c-.13-.69.08-1.3.57-1.77l-2.06-2.07a1.12 1.12 0 0 0-1.56 0c-.15.15-.22.34-.27.53L12.07 9z"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M14.74 8.3a1.13 1.13 0 0 0-.73-.5.67.67 0 0 0-.53.13c-.15.12-.59.46-.2 1.3l1.18 2.5a.45.45 0 0 1-.23.76.44.44 0 0 1-.48-.25L7.6 6.11a.82.82 0 1 0-1.15 1.15l3.64 3.64a.45.45 0 1 1-.63.63L5.83 7.9 4.8 6.86a.82.82 0 0 0-1.33.9c.04.1.1.18.18.26l1.02 1.03 3.65 3.64a.44.44 0 0 1-.15.73.44.44 0 0 1-.48-.1L4.05 9.68a.82.82 0 0 0-1.4.57.81.81 0 0 0 .24.58l1.53 1.54 2.3 2.28a.45.45 0 0 1-.64.63L3.8 13a.81.81 0 0 0-1.39.57c0 .22.09.43.24.58l4.4 4.4c2.8 2.8 5.5 4.12 8.68.94 2.27-2.28 2.71-4.6 1.34-7.1l-2.32-4.08z"></path></svg></div></div></div><div class="pw-multi-vote-count l pl pm pn po pp pq pr"><p class="bm b hi bo cn"><span class="pd">--</span></p></div></div></span><span class="l h g f ps pt"><div class="o ao hc"><div class="pw-multi-vote-icon do oz pa pb pc"><div class=""><div class="dr pd de pe pf pg ph bb pi pj pk pc"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM15.42 1.84l-1.18-.39-.34 2.5 1.52-2.1zM9.76 1.45l-1.19.4 1.53 2.1-.34-2.5zM20.25 11.84l-2.5-4.4a1.42 1.42 0 0 0-.93-.64.96.96 0 0 0-.75.18c-.25.19-.4.42-.45.7l.05.05 2.35 4.13c1.62 2.95 1.1 5.78-1.52 8.4l-.46.41c1-.13 1.93-.6 2.78-1.45 2.7-2.7 2.51-5.59 1.43-7.38zM12.07 9.01c-.13-.69.08-1.3.57-1.77l-2.06-2.07a1.12 1.12 0 0 0-1.56 0c-.15.15-.22.34-.27.53L12.07 9z"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M14.74 8.3a1.13 1.13 0 0 0-.73-.5.67.67 0 0 0-.53.13c-.15.12-.59.46-.2 1.3l1.18 2.5a.45.45 0 0 1-.23.76.44.44 0 0 1-.48-.25L7.6 6.11a.82.82 0 1 0-1.15 1.15l3.64 3.64a.45.45 0 1 1-.63.63L5.83 7.9 4.8 6.86a.82.82 0 0 0-1.33.9c.04.1.1.18.18.26l1.02 1.03 3.65 3.64a.44.44 0 0 1-.15.73.44.44 0 0 1-.48-.1L4.05 9.68a.82.82 0 0 0-1.4.57.81.81 0 0 0 .24.58l1.53 1.54 2.3 2.28a.45.45 0 0 1-.64.63L3.8 13a.81.81 0 0 0-1.39.57c0 .22.09.43.24.58l4.4 4.4c2.8 2.8 5.5 4.12 8.68.94 2.27-2.28 2.71-4.6 1.34-7.1l-2.32-4.08z"></path></svg></div></div></div><div class="pw-multi-vote-count l pl pm pn po pp pq pr"><p class="bm b hi bo cn"><span class="pd">--</span></p></div></div></span></div><div class="pu o"><div><div class="ci" aria-hidden="false"><button class="pw dr px o ao de py pz" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="responses" class="pv"><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="bm b bn bo cn"><span class="pw-responses-count qa pv qb">64</span></p></button></div></div></div></div><div class="o ao"><div class="ci" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="ci" aria-hidden="false"><button class="au av aw ax ay az ba hz bc bd be bf bg bh bi qc ia qd" aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M15.22 4.93a.42.42 0 0 1-.12.13h.01a.45.45 0 0 1-.29.08.52.52 0 0 1-.3-.13L12.5 3v7.07a.5.5 0 0 1-.5.5.5.5 0 0 1-.5-.5V3.02l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.8a.42.42 0 0 1 .07.5zm-.1.14zm.88 2h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11a2 2 0 0 1-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.14c.1.1.15.22.15.35a.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9V8.96c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1z" fill="#000"></path></svg></button></div></div></div><div class="qe l fr"></div></div></div></div></div></div></footer></div><div class="o dx"><div class="em ce fa fb fc fd fe ff fg fh fi"></div></div><div class="l"><div class="l qf ov"><div class="l ov"><div class="qg qh l qf"><div class="o dx"><div class="em ce fa fb fc fd fe ff fg fh fi"><div class="o ao u"><h2 class="bm mw lh lj qi lk ll ln qj lo kr lq qk lr kv lt ql lu kz lw qm lx fs fu fv fw fx fy fz ga"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://towardsdatascience.com/?source=post_page-----3bd2b1164a53--------------------------------" rel="noopener follow">More from Towards Data Science</a></h2></div><div class="qn l"><p class="bm b bn bo cn">Your home for data science. A Medium publication sharing concepts, ideas and codes.</p></div></div></div></div></div><div class="qo l"><div class="qp qq l"><div class="ke l bl"><a class="bm b bn bo hj bq hl hm hn ho hp bd bz hq hr hs cd cf cg ch ci cj" href="https://towardsdatascience.com/?source=post_page-----3bd2b1164a53--------------------------------" rel="noopener follow">Read more from <!-- -->Towards Data Science</a></div></div></div><div class="o dx"><div class="em ce fa fb fc fd fe ff fg fh fi"><div class="qr qq l"><section class="pw-more-medium-articles l"><div class="qs l"><h2 class="bm mw lh lj qi lk ll ln qj lo kr lq qk lr kv lt ql lu kz lw qm lx fs fu fv fw fx fy fz ga">Recommended from Medium</h2></div><div class="gy o hc ht qt qu qv qw qx qy qz ra rb rc rd re rf rg rh"><div class="ri rj rk rl rm rn ro rp rq rr rs rt ru rv rw rx ry rz sa sb sc"><div class="ce ag"><div class="sd l"><div class="se o da dx"><div class="o hc u"><div class="sf o da sg"><div class="sh o ao"><div class="si l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://viraajkadam.medium.com/?source=post_internal_links---------0----------------------------" rel="noopener follow"><div class="l do"><img alt="Viraj Kadam" class="l ch fl sj sk fp" src="https://miro.medium.com/fit/c/40/40/1*dmbNkD5D-u45r44go_cf0g.png" width="20" height="20" loading="lazy"/><div class="fk fl l sj sk fo aq"></div></div></a></div><div class="hy l"><div><div class="ci" aria-hidden="false"><div class="o"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://viraajkadam.medium.com/?source=post_internal_links---------0----------------------------" rel="noopener follow"><p class="bm b hi bo fs ft fu fv fw fx fy fz ga">Viraj Kadam</p></a></div></div></div></div></div><a href="https://viraajkadam.medium.com/loading-multi-band-satellite-images-in-tensorflow-data-pipelines-a0dd7885a98?source=post_internal_links---------0----------------------------" rel="noopener follow"><h2 class="bm iz dm bo fs sl fu fv sm fx fz ix ga"><div>Loading Multi-band satellite images in tensorflow data pipelines</div></h2></a></div><a href="https://viraajkadam.medium.com/loading-multi-band-satellite-images-in-tensorflow-data-pipelines-a0dd7885a98?source=post_internal_links---------0----------------------------" rel="noopener follow"><div class="sn l"><div class="m fs l do fp"><div class="so sp l"><img alt="" class="sq" src="https://miro.medium.com/focal/112/112/50/50/1*ZTWffsdfQFebOcwTB2IEzg.png" width="56" loading="lazy" role="presentation"/></div></div></div></a></div></div></div></div></div><div class="ri rj rk rl rm rn ro rp rq rr rs rt ru rv rw rx ry rz sa sb sc"><div class="ce ag"><div class="sd l"><div class="se o da dx"><div class="o hc u"><div class="sf o da sg"><div class="sh o ao"><div class="si l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/@lukemenzies?source=post_internal_links---------1----------------------------" rel="noopener follow"><div class="l do"><img alt="Luke Menzies" class="l ch fl sj sk fp" src="https://miro.medium.com/fit/c/40/40/1*yBu5aDVYFXqHujp5SRgb8w.jpeg" width="20" height="20" loading="lazy"/><div class="fk fl l sj sk fo aq"></div></div></a></div><div class="hy l"><div><div class="ci" aria-hidden="false"><div class="o"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/@lukemenzies?source=post_internal_links---------1----------------------------" rel="noopener follow"><p class="bm b hi bo fs ft fu fv fw fx fy fz ga">Luke Menzies</p></a></div></div></div></div></div><a href="https://medium.com/@lukemenzies/distil8-solution-accelerators-b36cfc03ff0a?source=post_internal_links---------1----------------------------" rel="noopener follow"><h2 class="bm iz dm bo fs sl fu fv sm fx fz ix ga"><div>Distil8 — Solution Accelerators</div></h2></a></div><a href="https://medium.com/@lukemenzies/distil8-solution-accelerators-b36cfc03ff0a?source=post_internal_links---------1----------------------------" rel="noopener follow"><div class="sn l"><div class="m fs l do fp"><div class="so sp l"><img alt="" class="sq" src="https://miro.medium.com/focal/112/112/50/50/1*SiQ6IOXfcTjT4bQdUPewnA.png" width="56" loading="lazy" role="presentation"/></div></div></div></a></div></div></div></div></div><div class="ri rj rk rl rm rn ro rp rq rr rs rt ru rv rw rx ry rz sa sb sc"><div class="ce ag"><div class="sd l"><div class="se o da dx"><div class="o hc u"><div class="sf o da sg"><div class="sh o ao"><div class="si l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://david-exiga.medium.com/?source=post_internal_links---------2----------------------------" rel="noopener follow"><div class="l do"><img alt="David C Exiga" class="l ch fl sj sk fp" src="https://miro.medium.com/fit/c/40/40/0*faBhW5Ch94aNWl68" width="20" height="20" loading="lazy"/><div class="fk fl l sj sk fo aq"></div></div></a></div><div class="hy l"><div><div class="ci" aria-hidden="false"><div class="o"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://david-exiga.medium.com/?source=post_internal_links---------2----------------------------" rel="noopener follow"><p class="bm b hi bo fs ft fu fv fw fx fy fz ga">David C Exiga</p></a></div></div></div></div></div><a href="https://david-exiga.medium.com/music-generation-using-lstm-neural-networks-44f6780a4c5?source=post_internal_links---------2----------------------------" rel="noopener follow"><h2 class="bm iz dm bo fs sl fu fv sm fx fz ix ga"><div>Music Generation Using LSTM Neural Networks</div></h2></a></div><a href="https://david-exiga.medium.com/music-generation-using-lstm-neural-networks-44f6780a4c5?source=post_internal_links---------2----------------------------" rel="noopener follow"><div class="sn l"><div class="m fs l do fp"><div class="so sp l"><img alt="" class="sq" src="https://miro.medium.com/focal/112/112/50/50/0*tcx2eTZLxxpy1ncK" width="56" loading="lazy" role="presentation"/></div></div></div></a></div></div></div></div></div><div class="ri rj rk rl rm rn ro rp rq rr rs rt ru rv rw rx ry rz sa sb sc"><div class="ce ag"><div class="sd l"><div class="se o da dx"><div class="o hc u"><div class="sf o da sg"><div class="sh o ao"><div class="si l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://matthew-g.medium.com/?source=post_internal_links---------3----------------------------" rel="noopener follow"><div class="l do"><img alt="Matthew Grey" class="l ch fl sj sk fp" src="https://miro.medium.com/fit/c/40/40/1*swNF-1ZWqMmJR52Tp2K1_A.png" width="20" height="20" loading="lazy"/><div class="fk fl l sj sk fo aq"></div></div></a></div><div class="hy l"><div><div class="ci" aria-hidden="false"><div class="o"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://matthew-g.medium.com/?source=post_internal_links---------3----------------------------" rel="noopener follow"><p class="bm b hi bo fs ft fu fv fw fx fy fz ga">Matthew Grey</p></a></div></div></div></div><div class="hy l"><p class="bm b hi bo cn">in</p></div><div class="l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://servian.dev/?source=post_internal_links---------3----------------------------" rel="noopener follow"><p class="bm b hi bo fs ft fu fv fw fx fy fz ga">Servian</p></a></div></div><a href="https://servian.dev/automating-document-comprehension-in-one-week-22f47b3dc50d?source=post_internal_links---------3----------------------------" rel="noopener follow"><h2 class="bm iz dm bo fs sl fu fv sm fx fz ix ga"><div>Automating Document Comprehension in One Week</div></h2></a></div><a href="https://servian.dev/automating-document-comprehension-in-one-week-22f47b3dc50d?source=post_internal_links---------3----------------------------" rel="noopener follow"><div class="sn l"><div class="m fs l do fp"><div class="so sp l"><img alt="A library bookshelf" class="sq" src="https://miro.medium.com/focal/112/112/50/50/1*PpvYTXsVy9vPZSkzlZ6QcQ.jpeg" width="56" loading="lazy"/></div></div></div></a></div></div></div></div></div><div class="ri rj rk rl rm rn ro rp rq rr rs rt ru rv rw rx ry rz sa sb sc"><div class="ce ag"><div class="sd l"><div class="se o da dx"><div class="o hc u"><div class="sf o da sg"><div class="sh o ao"><div class="si l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://alan-ratliff.medium.com/?source=post_internal_links---------4----------------------------" rel="noopener follow"><div class="l do"><img alt="Alan Ratliff" class="l ch fl sj sk fp" src="https://miro.medium.com/fit/c/40/40/1*UsdNYRSsr8YMyQpSmpNxZA@2x.jpeg" width="20" height="20" loading="lazy"/><div class="fk fl l sj sk fo aq"></div></div></a></div><div class="hy l"><div><div class="ci" aria-hidden="false"><div class="o"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://alan-ratliff.medium.com/?source=post_internal_links---------4----------------------------" rel="noopener follow"><p class="bm b hi bo fs ft fu fv fw fx fy fz ga">Alan Ratliff</p></a></div></div></div></div></div><a href="https://alan-ratliff.medium.com/using-supervised-machine-learning-in-elections-8ebe6d16346c?source=post_internal_links---------4----------------------------" rel="noopener follow"><h2 class="bm iz dm bo fs sl fu fv sm fx fz ix ga"><div>Using Supervised Machine Learning in Elections</div></h2></a></div><a href="https://alan-ratliff.medium.com/using-supervised-machine-learning-in-elections-8ebe6d16346c?source=post_internal_links---------4----------------------------" rel="noopener follow"><div class="sn l"><div class="m fs l do fp"><div class="so sp l"><img alt="" class="sq" src="https://miro.medium.com/focal/112/112/50/50/1*rkH7AepwMs2eoPSxLG2L_Q.png" width="56" loading="lazy" role="presentation"/></div></div></div></a></div></div></div></div></div><div class="ri rj rk rl rm rn ro rp rq rr rs rt ru rv rw rx ry rz sa sb sc"><div class="ce ag"><div class="sd l"><div class="se o da dx"><div class="o hc u"><div class="sf o da sg"><div class="sh o ao"><div class="si l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://vitalitylearning.medium.com/?source=post_internal_links---------5----------------------------" rel="noopener follow"><div class="l do"><img alt="Vitality Learning" class="l ch fl sj sk fp" src="https://miro.medium.com/fit/c/40/40/1*bMfUiKGXjiHAiIG-yvz_6A.png" width="20" height="20" loading="lazy"/><div class="fk fl l sj sk fo aq"></div></div></a></div><div class="hy l"><div><div class="ci" aria-hidden="false"><div class="o"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://vitalitylearning.medium.com/?source=post_internal_links---------5----------------------------" rel="noopener follow"><p class="bm b hi bo fs ft fu fv fw fx fy fz ga">Vitality Learning</p></a></div></div></div></div></div><a href="https://vitalitylearning.medium.com/nearest-neighbor-with-tensorflow-a3875eaaa9a3?source=post_internal_links---------5----------------------------" rel="noopener follow"><h2 class="bm iz dm bo fs sl fu fv sm fx fz ix ga"><div>Nearest neighbor with TensorFlow</div></h2></a></div><a href="https://vitalitylearning.medium.com/nearest-neighbor-with-tensorflow-a3875eaaa9a3?source=post_internal_links---------5----------------------------" rel="noopener follow"><div class="sn l"><div class="m fs l do fp"><div class="so sp l"><img alt="" class="sq" src="https://miro.medium.com/focal/112/112/50/50/0*9ZuzIFdaa3aC3l-r" width="56" loading="lazy" role="presentation"/></div></div></div></a></div></div></div></div></div><div class="ri rj rk rl rm rn ro rp rq rr rs rt ru rv rw rx ry rz sa sb sc"><div class="ce ag"><div class="sd l"><div class="se o da dx"><div class="o hc u"><div class="sf o da sg"><div class="sh o ao"><div class="si l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://jeyasrisubramanian.medium.com/?source=post_internal_links---------6----------------------------" rel="noopener follow"><div class="l do"><img alt="Jeyasri Subramanian" class="l ch fl sj sk fp" src="https://miro.medium.com/fit/c/40/40/0*j_lisS9Lwr_zDiBl" width="20" height="20" loading="lazy"/><div class="fk fl l sj sk fo aq"></div></div></a></div><div class="hy l"><div><div class="ci" aria-hidden="false"><div class="o"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://jeyasrisubramanian.medium.com/?source=post_internal_links---------6----------------------------" rel="noopener follow"><p class="bm b hi bo fs ft fu fv fw fx fy fz ga">Jeyasri Subramanian</p></a></div></div></div></div></div><a href="https://jeyasrisubramanian.medium.com/a-survey-on-few-shot-learning-ad0e768fa5f4?source=post_internal_links---------6----------------------------" rel="noopener follow"><h2 class="bm iz dm bo fs sl fu fv sm fx fz ix ga"><div>A survey on Few shot learning</div></h2></a></div><a href="https://jeyasrisubramanian.medium.com/a-survey-on-few-shot-learning-ad0e768fa5f4?source=post_internal_links---------6----------------------------" rel="noopener follow"><div class="sn l"><div class="m fs l do fp"><div class="so sp l"><img alt="" class="sq" src="https://miro.medium.com/focal/112/112/50/50/1*jPWFkuY3F5UAqT_809FMOA.png" width="56" loading="lazy" role="presentation"/></div></div></div></a></div></div></div></div></div><div class="ri rj rk rl rm rn ro rp rq rr rs rt ru rv rw rx ry rz sa sb sc"><div class="ce ag"><div class="sd l"><div class="se o da dx"><div class="o hc u"><div class="sf o da sg"><div class="sh o ao"><div class="si l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/@ragsec0?source=post_internal_links---------7----------------------------" rel="noopener follow"><div class="l do"><img alt="Ricardo Garcia" class="l ch fl sj sk fp" src="https://miro.medium.com/fit/c/40/40/0*dokdoY4LnZq0FJDB" width="20" height="20" loading="lazy"/><div class="fk fl l sj sk fo aq"></div></div></a></div><div class="hy l"><div><div class="ci" aria-hidden="false"><div class="o"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/@ragsec0?source=post_internal_links---------7----------------------------" rel="noopener follow"><p class="bm b hi bo fs ft fu fv fw fx fy fz ga">Ricardo Garcia</p></a></div></div></div></div></div><a href="https://medium.com/@ragsec0/attention-is-all-you-need-a-gentle-explanation-for-the-transformers-model-123f2f2863a6?source=post_internal_links---------7----------------------------" rel="noopener follow"><h2 class="bm iz dm bo fs sl fu fv sm fx fz ix ga"><div>Attention is all you need: A gentle explanation for The Transformers model.</div></h2></a></div><a href="https://medium.com/@ragsec0/attention-is-all-you-need-a-gentle-explanation-for-the-transformers-model-123f2f2863a6?source=post_internal_links---------7----------------------------" rel="noopener follow"><div class="sn l"><div class="m fs l do fp"><div class="so sp l"><img alt="" class="sq" src="https://miro.medium.com/focal/112/112/50/50/1*Ipw5BmOTkawjtjLEB0DtxQ.png" width="56" loading="lazy" role="presentation"/></div></div></div></a></div></div></div></div></div></div></section></div></div></div></div></div><div class="d"><div class="sr ss st l os ar ed as su sv"><div class="o dx"><div class="fa fb sw sx sy sz em ce"><a class="au av aw ax ay az ba bb bc bd ta tb bg tc td" aria-label="Go to homepage" href="https://medium.com/?source=post_page-----3bd2b1164a53--------------------------------" rel="noopener follow"><svg viewBox="0 0 3940 610" class="hl te"><path d="M594.79 308.2c0 163.76-131.85 296.52-294.5 296.52S5.8 472 5.8 308.2 137.65 11.69 300.29 11.69s294.5 132.75 294.5 296.51M917.86 308.2c0 154.16-65.93 279.12-147.25 279.12s-147.25-125-147.25-279.12S689.29 29.08 770.61 29.08s147.25 125 147.25 279.12M1050 308.2c0 138.12-23.19 250.08-51.79 250.08s-51.79-112-51.79-250.08 23.19-250.08 51.8-250.08S1050 170.09 1050 308.2M1862.77 37.4l.82-.18v-6.35h-167.48l-155.51 365.5-155.51-365.5h-180.48v6.35l.81.18c30.57 6.9 46.09 17.19 46.09 54.3v434.45c0 37.11-15.58 47.4-46.15 54.3l-.81.18V587H1327v-6.35l-.81-.18c-30.57-6.9-46.09-17.19-46.09-54.3V116.9L1479.87 587h11.33l205.59-483.21V536.9c-2.62 29.31-18 38.36-45.68 44.61l-.82.19v6.3h213.3v-6.3l-.82-.19c-27.71-6.25-43.46-15.3-46.08-44.61l-.14-445.2h.14c0-37.11 15.52-47.4 46.08-54.3m97.43 287.8c3.49-78.06 31.52-134.4 78.56-135.37 14.51.24 26.68 5 36.14 14.16 20.1 19.51 29.55 60.28 28.09 121.21zm-2.11 22h250v-1.05c-.71-59.69-18-106.12-51.34-138-28.82-27.55-71.49-42.71-116.31-42.71h-1c-23.26 0-51.79 5.64-72.09 15.86-23.11 10.7-43.49 26.7-60.45 47.7-27.3 33.83-43.84 79.55-47.86 130.93-.13 1.54-.24 3.08-.35 4.62s-.18 2.92-.25 4.39a332.64 332.64 0 0 0-.36 21.69C1860.79 507 1923.65 600 2035.3 600c98 0 155.07-71.64 169.3-167.8l-7.19-2.53c-25 51.68-69.9 83-121 79.18-69.76-5.22-123.2-75.95-118.35-161.63m532.69 157.68c-8.2 19.45-25.31 30.15-48.24 30.15s-43.89-15.74-58.78-44.34c-16-30.7-24.42-74.1-24.42-125.51 0-107 33.28-176.21 84.79-176.21 21.57 0 38.55 10.7 46.65 29.37zm165.84 76.28c-30.57-7.23-46.09-18-46.09-57V5.28L2424.77 60v6.7l1.14-.09c25.62-2.07 43 1.47 53.09 10.79 7.9 7.3 11.75 18.5 11.75 34.26v71.14c-18.31-11.69-40.09-17.38-66.52-17.38-53.6 0-102.59 22.57-137.92 63.56-36.83 42.72-56.3 101.1-56.3 168.81C2230 518.72 2289.53 600 2378.13 600c51.83 0 93.53-28.4 112.62-76.3V588h166.65v-6.66zm159.29-505.33c0-37.76-28.47-66.24-66.24-66.24-37.59 0-67 29.1-67 66.24s29.44 66.24 67 66.24c37.77 0 66.24-28.48 66.24-66.24m43.84 505.33c-30.57-7.23-46.09-18-46.09-57h-.13V166.65l-166.66 47.85v6.5l1 .09c36.06 3.21 45.93 15.63 45.93 57.77V588h166.8v-6.66zm427.05 0c-30.57-7.23-46.09-18-46.09-57V166.65L3082 212.92v6.52l.94.1c29.48 3.1 38 16.23 38 58.56v226c-9.83 19.45-28.27 31-50.61 31.78-36.23 0-56.18-24.47-56.18-68.9V166.66l-166.66 47.85V221l1 .09c36.06 3.2 45.94 15.62 45.94 57.77v191.27a214.48 214.48 0 0 0 3.47 39.82l3 13.05c14.11 50.56 51.08 77 109 77 49.06 0 92.06-30.37 111-77.89v66h166.66v-6.66zM3934.2 588v-6.67l-.81-.19c-33.17-7.65-46.09-22.07-46.09-51.43v-243.2c0-75.83-42.59-121.09-113.93-121.09-52 0-95.85 30.05-112.73 76.86-13.41-49.6-52-76.86-109.06-76.86-50.12 0-89.4 26.45-106.25 71.13v-69.87l-166.66 45.89v6.54l1 .09c35.63 3.16 45.93 15.94 45.93 57V588h155.5v-6.66l-.82-.2c-26.46-6.22-35-17.56-35-46.66V255.72c7-16.35 21.11-35.72 49-35.72 34.64 0 52.2 24 52.2 71.28V588h155.54v-6.66l-.82-.2c-26.46-6.22-35-17.56-35-46.66v-248a160.45 160.45 0 0 0-2.2-27.68c7.42-17.77 22.34-38.8 51.37-38.8 35.13 0 52.2 23.31 52.2 71.28V588z"></path></svg></a><div class="tf l"><p class="bm b hi bo tg"><a class="au av aw ax ay az ba bb bc bd th bg tc td ol" href="https://medium.com/about?autoplay=1&amp;source=post_page-----3bd2b1164a53--------------------------------" rel="noopener follow">About</a><a class="au av aw ax ay az ba bb bc bd th bg tc td ol" href="https://help.medium.com/hc/en-us?source=post_page-----3bd2b1164a53--------------------------------" rel="noopener follow">Help</a><a class="au av aw ax ay az ba bb bc bd th bg tc td ol" href="https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----3bd2b1164a53--------------------------------" rel="noopener follow">Terms</a><a class="au av aw ax ay az ba bb bc bd th bg tc td" href="https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----3bd2b1164a53--------------------------------" rel="noopener follow">Privacy</a></p></div><div class="j i d"><hr class="dr ds ti tj" aria-hidden="true"/><h2 class="bm mw dm bo ix tg">Get the Medium app</h2><div class="tf o"><div class="fj l"><a class="au av aw ax ay az ba bb bc bd ta tb bg tc td" href="https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&amp;mt=8&amp;ct=post_page&amp;source=post_page-----3bd2b1164a53--------------------------------" rel="noopener follow"><img alt="A button that says &#x27;Download on the App Store&#x27;, and if clicked it will lead you to the iOS App store" class="" src="https://miro.medium.com/max/270/1*Crl55Tm6yDNMoucPo1tvDg.png" width="135" height="41" loading="lazy"/></a></div><a class="au av aw ax ay az ba bb bc bd ta tb bg tc td" href="https://play.google.com/store/apps/details?id=com.medium.reader&amp;source=post_page-----3bd2b1164a53--------------------------------" rel="noopener follow"><img alt="A button that says &#x27;Get it on, Google Play&#x27;, and if clicked it will lead you to the Google Play store" class="" src="https://miro.medium.com/max/270/1*W_RAPQ62h0em559zluJLdQ.png" width="135" height="41" loading="lazy"/></a></div></div></div></div></div></div></div></main><div class="eo ch c ep h k j i cu eq er es"><div class="ag ce ci do"><div class="l db aq"><div class="eq o da"><div class="l ou"><div class="tk tl tm l"><div class="l"><div class="o ao"><div class="pw-susi-button l ou"><span><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53&amp;source=post_page---three_column_layout_sidebar-----------------------three_column_layout_nav-----------" rel="noopener follow"><button class="bm b bn bo bp bq br bs bt bu bv bw bx by bz ca cb cc cd ce cf cg ch ci cj" aria-label="sign up">Get started</button></a></span></div></div></div></div><div class="tk tl tm l"><div class="o ii tn to"><div class="ci" aria-hidden="false" aria-describedby="searchResults" aria-labelledby="searchResults"></div><span class="tt l"><svg width="25" height="25" viewBox="0 0 25 25" fill="rgba(8, 8, 8, 1)"><path d="M20.07 18.93l-4.16-4.15a6 6 0 1 0-.88.88l4.15 4.16a.62.62 0 1 0 .89-.89zM6.5 11a4.75 4.75 0 1 1 9.5 0 4.75 4.75 0 0 1-9.5 0z"></path></svg></span><input role="combobox" aria-controls="searchResults" aria-expanded="false" aria-label="search" tabindex="0" class="dz tp bm bn bo ce tq tr ga ts" placeholder="Search" value=""/></div></div><div class="tk tl tm l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/@_sumitsaha_?source=---three_column_layout_sidebar----------------------------------" rel="noopener follow"><div class="l do"><img alt="Sumit Saha" class="l ch fl tu tv fp" src="https://miro.medium.com/fit/c/176/176/1*lYtVkQBgiPiHBemkYIDUwg.jpeg" width="88" height="88" loading="lazy"/><div class="fk fl l tu tv fo aq"></div></div></a><div class="tw l"></div><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/@_sumitsaha_?source=---three_column_layout_sidebar----------------------------------" rel="noopener follow"><h2 class="pw-author-name bm mw dm bo ix ga"><span class="ir">Sumit Saha</span></h2></a><div class="tx l"></div><span class="pw-follower-count bm b dm dn cn"><button class="au av aw ax ay az ba bb bc bd be bf bg bh bi">1.7K Followers</button></span><div class="nh l"></div><p class="bm b bn bo cn"><span class="ir">Data Scientist | Software Engineer | Writer</span></p><div class="ty l"></div><div class="tz o"><span><a class="bm b bn bo hj bq hl hm hn ho hp bd bz hq hr hs cd ua cf cg ch ci cj" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F631ee5e6343e&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53&amp;user=Sumit+Saha&amp;userId=631ee5e6343e&amp;source=post_page-631ee5e6343e--three_column_layout_sidebar-----------------------follow_profile-----------" rel="noopener follow">Follow</a></span><div class="ub l"><div><div><div class="ci" aria-hidden="false"><div class="l"><span><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F466f41a7e268&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53&amp;newsletterV3=631ee5e6343e&amp;newsletterV3Id=466f41a7e268&amp;user=Sumit+Saha&amp;userId=631ee5e6343e&amp;source=---three_column_layout_sidebar-----------------------subscribe_user-----------" rel="noopener follow"><button class="bm b bn bo bp bb br bs bt bu bv bw bx by bz hq hr hs cd cf cg ch ci cj" aria-label="Subscribe"><svg width="38" height="38" viewBox="0 0 38 38" fill="none" class="uc ud ue"><rect x="26.25" y="9.25" width="0.5" height="6.5" rx="0.25"></rect><rect x="29.75" y="12.25" width="0.5" height="6.5" rx="0.25" transform="rotate(90 29.75 12.25)"></rect><path d="M19.5 12.5h-7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1v-5"></path><path d="M11.5 14.5L19 20l4-3"></path></svg></button></a></span></div></div></div></div></div></div></div><div class="tk tl tm l"></div></div><div class="uf o hc ht"><div class="ug l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://help.medium.com/hc/en-us?source=---three_column_layout_sidebar----------------------------------" rel="noopener follow"><p class="bm b uh ui cn">Help</p></a></div><div class="ug l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.statuspage.io/?source=---three_column_layout_sidebar----------------------------------" rel="noopener follow"><p class="bm b uh ui cn">Status</p></a></div><div class="ug l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://about.medium.com/creators/?source=---three_column_layout_sidebar----------------------------------" rel="noopener follow"><p class="bm b uh ui cn">Writers</p></a></div><div class="ug l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://blog.medium.com/?source=---three_column_layout_sidebar----------------------------------" rel="noopener follow"><p class="bm b uh ui cn">Blog</p></a></div><div class="ug l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---three_column_layout_sidebar----------------------------------" rel="noopener follow"><p class="bm b uh ui cn">Careers</p></a></div><div class="ug l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---three_column_layout_sidebar----------------------------------" rel="noopener follow"><p class="bm b uh ui cn">Privacy</p></a></div><div class="ug l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---three_column_layout_sidebar----------------------------------" rel="noopener follow"><p class="bm b uh ui cn">Terms</p></a></div><div class="ug l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://medium.com/about?autoplay=1&amp;source=---three_column_layout_sidebar----------------------------------" rel="noopener follow"><p class="bm b uh ui cn">About</p></a></div><div class="ug l"><a class="au av aw ax ay az ba bb bc bd be bf bg bh bi" href="https://knowable.fyi/?source=---three_column_layout_sidebar----------------------------------" rel="noopener follow"><p class="bm b uh ui cn">Knowable</p></a></div></div></div></div></div></div></div></div></div></div></div><script>window.__BUILD_ID__="main-20221028-171048-1ab39ad032"</script><script>window.__GRAPHQL_URI__ = "https://towardsdatascience.com/_/graphql"</script><script>window.__PRELOADED_STATE__ = {"algolia":{"queries":{}},"auroraPage":{"isAuroraPageEnabled":false},"cache":{"experimentGroupSet":true,"reason":"","group":"enabled","tags":["group-edgeCachePosts","post-3bd2b1164a53","user-631ee5e6343e","collection-7f60cf5620c9"],"serverVariantState":"44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a","middlewareEnabled":true,"cacheStatus":"DYNAMIC","shouldUseCache":true,"vary":[],"inDisabledExperiment":false,"zenEnabled":false},"client":{"hydrated":false,"isUs":false,"isNativeMedium":false,"isSafariMobile":false,"isSafari":false,"isFirefox":false,"routingEntity":{"type":"COLLECTION","id":"7f60cf5620c9","explicit":true},"viewerIsBot":false},"debug":{"requestId":"59eb4f2f-c20b-4347-8d43-c5c8121893e9","hybridDevServices":[],"originalSpanCarrier":{"ot-tracer-spanid":"466260ac2a364535","ot-tracer-traceid":"5cf9fb5bfb95789d","ot-tracer-sampled":"true"}},"meter":{},"multiVote":{"clapsPerPost":{}},"navigation":{"branch":{"show":null,"hasRendered":null,"blockedByCTA":false},"hideGoogleOneTap":false,"hasRenderedAlternateUserBanner":null,"currentLocation":"https:\u002F\u002Ftowardsdatascience.com\u002Fa-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53","host":"towardsdatascience.com","hostname":"towardsdatascience.com","referrer":"","hasSetReferrer":false,"susiModal":{"step":null,"operation":"register"},"postRead":false,"queryString":"","currentHash":""},"config":{"nodeEnv":"production","version":"main-20221028-171048-1ab39ad032","target":"production","productName":"Medium","publicUrl":"https:\u002F\u002Fcdn-client.medium.com\u002Flite","authDomain":"medium.com","authGoogleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","favicon":"production","glyphUrl":"https:\u002F\u002Fglyph.medium.com","branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","algolia":{"appId":"MQ57UUUQZ2","apiKeySearch":"394474ced050e3911ae2249ecc774921","indexPrefix":"medium_","host":"-dsn.algolia.net"},"recaptchaKey":"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk","recaptcha3Key":"6Lf8R9wUAAAAABMI_85Wb8melS7Zj6ziuf99Yot5","datadog":{"applicationId":"6702d87d-a7e0-42fe-bbcb-95b469547ea0","clientToken":"pub853ea8d17ad6821d9f8f11861d23dfed","rumToken":"pubf9cc52896502b9413b68ba36fc0c7162","context":{"deployment":{"target":"production","tag":"main-20221028-171048-1ab39ad032","commit":"1ab39ad0329a5c2ef168efb76cfd8de8e7517710"}},"datacenter":"us"},"googleAnalyticsCode":"UA-24232453-2","googlePay":{"apiVersion":"2","apiVersionMinor":"0","merchantId":"BCR2DN6TV7EMTGBM","merchantName":"Medium","instanceMerchantId":"13685562959212738550"},"applePay":{"version":3},"signInWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"mediumOwnedAndOperatedCollectionIds":["8a9336e5bb4","b7e45b22fec3","193b68bd4fba","8d6b8a439e32","54c98c43354d","3f6ecf56618","d944778ce714","92d2092dc598","ae2a65f35510","1285ba81cada","544c7006046e","fc8964313712","40187e704f1c","88d9857e584e","7b6769f2748b","bcc38c8f6edf","cef6983b292","cb8577c9149e","444d13b52878","713d7dbc99b0","ef8e90590e66","191186aaafa0","55760f21cdc5","9dc80918cc93","bdc4052bbdba","8ccfed20cbb2"],"tierOneDomains":["medium.com","thebolditalic.com","arcdigital.media","towardsdatascience.com","uxdesign.cc","codeburst.io","psiloveyou.xyz","writingcooperative.com","entrepreneurshandbook.co","prototypr.io","betterhumans.coach.me","theascent.pub"],"topicsToFollow":["d61cf867d93f","8a146bc21b28","1eca0103fff3","4d562ee63426","aef1078a3ef5","e15e46793f8d","6158eb913466","55f1c20aba7a","3d18b94f6858","4861fee224fd","63c6f1f93ee","1d98b3a9a871","decb52b64abf","ae5d4995e225","830cded25262"],"topicToTagMappings":{"accessibility":"accessibility","addiction":"addiction","android-development":"android-development","art":"art","artificial-intelligence":"artificial-intelligence","astrology":"astrology","basic-income":"basic-income","beauty":"beauty","biotech":"biotech","blockchain":"blockchain","books":"books","business":"business","cannabis":"cannabis","cities":"cities","climate-change":"climate-change","comics":"comics","coronavirus":"coronavirus","creativity":"creativity","cryptocurrency":"cryptocurrency","culture":"culture","cybersecurity":"cybersecurity","data-science":"data-science","design":"design","digital-life":"digital-life","disability":"disability","economy":"economy","education":"education","equality":"equality","family":"family","feminism":"feminism","fiction":"fiction","film":"film","fitness":"fitness","food":"food","freelancing":"freelancing","future":"future","gadgets":"gadgets","gaming":"gaming","gun-control":"gun-control","health":"health","history":"history","humor":"humor","immigration":"immigration","ios-development":"ios-development","javascript":"javascript","justice":"justice","language":"language","leadership":"leadership","lgbtqia":"lgbtqia","lifestyle":"lifestyle","machine-learning":"machine-learning","makers":"makers","marketing":"marketing","math":"math","media":"media","mental-health":"mental-health","mindfulness":"mindfulness","money":"money","music":"music","neuroscience":"neuroscience","nonfiction":"nonfiction","outdoors":"outdoors","parenting":"parenting","pets":"pets","philosophy":"philosophy","photography":"photography","podcasts":"podcast","poetry":"poetry","politics":"politics","privacy":"privacy","product-management":"product-management","productivity":"productivity","programming":"programming","psychedelics":"psychedelics","psychology":"psychology","race":"race","relationships":"relationships","religion":"religion","remote-work":"remote-work","san-francisco":"san-francisco","science":"science","self":"self","self-driving-cars":"self-driving-cars","sexuality":"sexuality","social-media":"social-media","society":"society","software-engineering":"software-engineering","space":"space","spirituality":"spirituality","sports":"sports","startups":"startup","style":"style","technology":"technology","transportation":"transportation","travel":"travel","true-crime":"true-crime","tv":"tv","ux":"ux","venture-capital":"venture-capital","visual-design":"visual-design","work":"work","world":"world","writing":"writing"},"defaultImages":{"avatar":{"imageId":"1*dmbNkD5D-u45r44go_cf0g.png","height":150,"width":150},"orgLogo":{"imageId":"1*OMF3fSqH8t4xBJ9-6oZDZw.png","height":106,"width":545},"postLogo":{"imageId":"1*kFrc4tBFM_tCis-2Ic87WA.png","height":810,"width":1440},"postPreviewImage":{"imageId":"1*hn4v1tCaJy7cWMyb0bpNpQ.png","height":386,"width":579}},"collectionStructuredData":{"8d6b8a439e32":{"name":"Elemental","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F980\u002F1*9ygdqoKprhwuTVKUM0DLPA@2x.png","width":980,"height":159}}},"3f6ecf56618":{"name":"Forge","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F596\u002F1*uULpIlImcO5TDuBZ6lm7Lg@2x.png","width":596,"height":183}}},"ae2a65f35510":{"name":"GEN","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F264\u002F1*RdVZMdvfV3YiZTw6mX7yWA.png","width":264,"height":140}}},"88d9857e584e":{"name":"LEVEL","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*JqYMhNX6KNNb2UlqGqO2WQ.png","width":540,"height":108}}},"7b6769f2748b":{"name":"Marker","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F383\u002F1*haCUs0wF6TgOOvfoY-jEoQ@2x.png","width":383,"height":92}}},"444d13b52878":{"name":"OneZero","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*cw32fIqCbRWzwJaoQw6BUg.png","width":540,"height":123}}},"8ccfed20cbb2":{"name":"Zora","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*tZUQqRcCCZDXjjiZ4bDvgQ.png","width":540,"height":106}}}},"embeddedPostIds":{"coronavirus":"cd3010f9d81f"},"sharedCdcMessaging":{"COVID_APPLICABLE_TAG_SLUGS":[],"COVID_APPLICABLE_TOPIC_NAMES":[],"COVID_APPLICABLE_TOPIC_NAMES_FOR_TOPIC_PAGE":[],"COVID_MESSAGES":{"tierA":{"text":"For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":66,"end":73,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"tierB":{"text":"Anyone can publish on Medium per our Policies, but we don’t fact-check every story. For more info about the coronavirus, see cdc.gov.","markups":[{"start":37,"end":45,"href":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Fcategories\u002F201931128-Policies-Safety"},{"start":125,"end":132,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"paywall":{"text":"This article has been made free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":56,"end":70,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":138,"end":145,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"unbound":{"text":"This article is free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":45,"end":59,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":127,"end":134,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]}},"COVID_BANNER_POST_ID_OVERRIDE_WHITELIST":["3b31a67bff4a"]},"sharedVoteMessaging":{"TAGS":["politics","election-2020","government","us-politics","election","2020-presidential-race","trump","donald-trump","democrats","republicans","congress","republican-party","democratic-party","biden","joe-biden","maga"],"TOPICS":["politics","election"],"MESSAGE":{"text":"Find out more about the U.S. election results here.","markups":[{"start":46,"end":50,"href":"https:\u002F\u002Fcookpolitical.com\u002F2020-national-popular-vote-tracker"}]},"EXCLUDE_POSTS":["397ef29e3ca5"]},"embedPostRules":[],"recircOptions":{"v1":{"limit":3},"v2":{"limit":8}},"braintreeClientKey":"production_zjkj96jm_m56f8fqpf7ngnrd4","braintree":{"enabled":true,"merchantId":"m56f8fqpf7ngnrd4","merchantAccountId":{"usd":"AMediumCorporation_instant","eur":"amediumcorporation_EUR","cad":"amediumcorporation_CAD"},"publicKey":"ds2nn34bg2z7j5gd","braintreeEnvironment":"production","dashboardUrl":"https:\u002F\u002Fwww.braintreegateway.com\u002Fmerchants","gracePeriodDurationInDays":14,"mediumMembershipPlanId":{"monthly":"ce105f8c57a3","monthlyWithTrial":"d5ee3dbe3db8","yearly":"a40ad4a43185","yearlyStaff":"d74fb811198a","yearlyWithTrial":"b3bc7350e5c7","monthlyCad":"p52orjkaceei","yearlyCad":"h4q9g2up9ktt"},"braintreeDiscountId":{"oneMonthFree":"MONTHS_FREE_01","threeMonthsFree":"MONTHS_FREE_03","sixMonthsFree":"MONTHS_FREE_06"},"3DSecureVersion":"2","defaultCurrency":"usd","providerPlanIdCurrency":{"4ycw":"usd","rz3b":"usd","3kqm":"usd","jzw6":"usd","c2q2":"usd","nnsw":"usd","fx7w":"cad","nwf2":"cad"}},"paypalClientId":"AXj1G4fotC2GE8KzWX9mSxCH1wmPE3nJglf4Z2ig_amnhvlMVX87otaq58niAg9iuLktVNF_1WCMnN7v","paypal":{"host":"https:\u002F\u002Fapi.paypal.com:443","clientMode":"production","serverMode":"live","webhookId":"4G466076A0294510S","monthlyPlan":{"planId":"P-9WR0658853113943TMU5FDQA","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlan":{"planId":"P-7N8963881P8875835MU5JOPQ","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oneYearGift":{"name":"Medium Membership (1 Year, Digital Gift Code)","description":"Unlimited access to the best and brightest stories on Medium. Gift codes can be redeemed at medium.com\u002Fredeem.","price":"50.00","currency":"USD","sku":"membership-gift-1-yr"},"oldMonthlyPlan":{"planId":"P-96U02458LM656772MJZUVH2Y","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlan":{"planId":"P-59P80963JF186412JJZU3SMI","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"monthlyPlanWithTrial":{"planId":"P-66C21969LR178604GJPVKUKY","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlanWithTrial":{"planId":"P-6XW32684EX226940VKCT2MFA","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oldMonthlyPlanNoSetupFee":{"planId":"P-4N046520HR188054PCJC7LJI","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlanNoSetupFee":{"planId":"P-7A4913502Y5181304CJEJMXQ","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"sdkUrl":"https:\u002F\u002Fwww.paypal.com\u002Fsdk\u002Fjs"},"stripePublishableKey":"pk_live_7FReX44VnNIInZwrIIx6ghjl","log":{"json":true,"level":"info"},"webpRamp":[],"imageUploadMaxSizeMb":25},"session":{"xsrf":""}}</script><script>window.__APOLLO_STATE__ = {"ROOT_QUERY":{"__typename":"Query","collectionByDomainOrSlug({\"domainOrSlug\":\"towardsdatascience.com\"})":{"__ref":"Collection:7f60cf5620c9"},"postResult({\"id\":\"3bd2b1164a53\"})":{"__ref":"Post:3bd2b1164a53"}},"ImageMetadata:1*VzTUkfeGymHP4Bvav-T-lA.png":{"__typename":"ImageMetadata","id":"1*VzTUkfeGymHP4Bvav-T-lA.png"},"Collection:7f60cf5620c9":{"__typename":"Collection","id":"7f60cf5620c9","favicon":{"__ref":"ImageMetadata:1*VzTUkfeGymHP4Bvav-T-lA.png"},"customStyleSheet":{"__ref":"CustomStyleSheet:514038af8f2f"},"colorPalette":{"__typename":"ColorPalette","highlightSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FFEDF4FC","point":0},{"__typename":"ColorPoint","color":"#FFE9F2FD","point":0.1},{"__typename":"ColorPoint","color":"#FFE6F1FD","point":0.2},{"__typename":"ColorPoint","color":"#FFE2EFFD","point":0.3},{"__typename":"ColorPoint","color":"#FFDFEEFD","point":0.4},{"__typename":"ColorPoint","color":"#FFDBECFE","point":0.5},{"__typename":"ColorPoint","color":"#FFD7EBFE","point":0.6},{"__typename":"ColorPoint","color":"#FFD4E9FE","point":0.7},{"__typename":"ColorPoint","color":"#FFD0E7FF","point":0.8},{"__typename":"ColorPoint","color":"#FFCCE6FF","point":0.9},{"__typename":"ColorPoint","color":"#FFC8E4FF","point":1}]},"defaultBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FF668AAA","point":0},{"__typename":"ColorPoint","color":"#FF61809D","point":0.1},{"__typename":"ColorPoint","color":"#FF5A7690","point":0.2},{"__typename":"ColorPoint","color":"#FF546C83","point":0.3},{"__typename":"ColorPoint","color":"#FF4D6275","point":0.4},{"__typename":"ColorPoint","color":"#FF455768","point":0.5},{"__typename":"ColorPoint","color":"#FF3D4C5A","point":0.6},{"__typename":"ColorPoint","color":"#FF34414C","point":0.7},{"__typename":"ColorPoint","color":"#FF2B353E","point":0.8},{"__typename":"ColorPoint","color":"#FF21282F","point":0.9},{"__typename":"ColorPoint","color":"#FF161B1F","point":1}]},"tintBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FF355876","colorPoints":[{"__typename":"ColorPoint","color":"#FF355876","point":0},{"__typename":"ColorPoint","color":"#FF4D6C88","point":0.1},{"__typename":"ColorPoint","color":"#FF637F99","point":0.2},{"__typename":"ColorPoint","color":"#FF7791A8","point":0.3},{"__typename":"ColorPoint","color":"#FF8CA2B7","point":0.4},{"__typename":"ColorPoint","color":"#FF9FB3C6","point":0.5},{"__typename":"ColorPoint","color":"#FFB2C3D4","point":0.6},{"__typename":"ColorPoint","color":"#FFC5D2E1","point":0.7},{"__typename":"ColorPoint","color":"#FFD7E2EE","point":0.8},{"__typename":"ColorPoint","color":"#FFE9F1FA","point":0.9},{"__typename":"ColorPoint","color":"#FFFBFFFF","point":1}]}},"googleAnalyticsId":null,"domain":"towardsdatascience.com","name":"Towards Data Science","slug":"towards-data-science","avatar":{"__ref":"ImageMetadata:1*CJe3891yB1A1mzMdqemkdg.jpeg"},"isAuroraVisible":true,"legacyHeaderBackgroundImage":null,"logo":{"__ref":"ImageMetadata:1*mG6i4Bh_LgixUYXJgQpYsg@2x.png"},"subscriberCount":646015,"newsletterV3":{"__ref":"NewsletterV3:d6fe9076899"},"navItems":[{"__typename":"NavItem","tagSlug":null,"title":"Data Science","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fdata-science\u002Fhome"},{"__typename":"NavItem","tagSlug":null,"title":"Machine Learning","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fmachine-learning\u002Fhome"},{"__typename":"NavItem","tagSlug":null,"title":"Programming","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fprogramming\u002Fhome"},{"__typename":"NavItem","tagSlug":null,"title":"Visualization","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fdata-visualization\u002Fhome"},{"__typename":"NavItem","tagSlug":null,"title":"Video","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fvideo\u002Fhome"},{"__typename":"NavItem","tagSlug":null,"title":"★","url":"https:\u002F\u002Ftowardsdatascience.com\u002Feditors-picks\u002Fhome"},{"__typename":"NavItem","tagSlug":null,"title":"About","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fabout-us\u002Fhome"},{"__typename":"NavItem","tagSlug":null,"title":"Contribute","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fcontribute\u002Fhome"}],"viewerEdge":{"__ref":"CollectionViewerEdge:collectionId:7f60cf5620c9-viewerId:lo_ff0caccbcd02"},"creator":{"__ref":"User:7e12c71dfa81"},"isAuroraEligible":true,"twitterUsername":"TDataScience","facebookPageId":null,"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","status":"ACTIVE","isSubdomain":false}},"ptsQualifiedAt":1616092952992,"description":"Your home for data science. A Medium publication sharing concepts, ideas and codes."},"UserViewerEdge:userId:631ee5e6343e-viewerId:lo_ff0caccbcd02":{"__typename":"UserViewerEdge","id":"userId:631ee5e6343e-viewerId:lo_ff0caccbcd02","isFollowing":false,"isUser":false},"NewsletterV3:466f41a7e268":{"__typename":"NewsletterV3","id":"466f41a7e268","type":"NEWSLETTER_TYPE_AUTHOR","slug":"631ee5e6343e","name":"631ee5e6343e","collection":null,"user":{"__ref":"User:631ee5e6343e"},"description":"","promoHeadline":"","promoBody":"","showPromo":false,"subscribersCount":20},"User:631ee5e6343e":{"__typename":"User","id":"631ee5e6343e","name":"Sumit Saha","username":"_sumitsaha_","newsletterV3":{"__ref":"NewsletterV3:466f41a7e268"},"imageId":"1*lYtVkQBgiPiHBemkYIDUwg.jpeg","socialStats":{"__typename":"SocialStats","followerCount":1730,"followingCount":45,"collectionFollowingCount":47},"customStyleSheet":null,"bio":"Data Scientist | Software Engineer | Writer","isPartnerProgramEnrolled":false,"viewerEdge":{"__ref":"UserViewerEdge:userId:631ee5e6343e-viewerId:lo_ff0caccbcd02"},"viewerIsUser":false,"postSubscribeMembershipUpsellShownAt":0,"customDomainState":null,"hasSubdomain":false,"mediumMemberAt":0,"about":"Data Scientist | Software Engineer https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Flinksumitsaha","homepagePostsConnection:{\"paging\":{\"limit\":1}}":{"__typename":"PostConnection","posts":[{"__ref":"Post:3bd2b1164a53"}]},"isSuspended":false,"allowNotes":true,"isAuroraVisible":true,"twitterScreenName":"_sumitsaha_","atsQualifiedAt":1612205711909},"Post:3bd2b1164a53":{"__typename":"Post","id":"3bd2b1164a53","firstPublishedAt":1544893414706,"visibility":"PUBLIC","creator":{"__ref":"User:631ee5e6343e"},"canonicalUrl":"","collection":{"__ref":"Collection:7f60cf5620c9"},"content({\"postMeteringOptions\":{\"forceTruncation\":false}})":{"__typename":"PostContent","isLockedPreviewOnly":false,"validatedShareKey":"","bodyModel":{"__typename":"RichText","sections":[{"__typename":"Section","name":"94ed","startIndex":0,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null},{"__typename":"Section","name":"02aa","startIndex":55,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null}],"paragraphs":[{"__ref":"Paragraph:11cb31db39a1_0"},{"__ref":"Paragraph:11cb31db39a1_1"},{"__ref":"Paragraph:11cb31db39a1_2"},{"__ref":"Paragraph:11cb31db39a1_3"},{"__ref":"Paragraph:11cb31db39a1_4"},{"__ref":"Paragraph:11cb31db39a1_5"},{"__ref":"Paragraph:11cb31db39a1_6"},{"__ref":"Paragraph:11cb31db39a1_7"},{"__ref":"Paragraph:11cb31db39a1_8"},{"__ref":"Paragraph:11cb31db39a1_9"},{"__ref":"Paragraph:11cb31db39a1_10"},{"__ref":"Paragraph:11cb31db39a1_11"},{"__ref":"Paragraph:11cb31db39a1_12"},{"__ref":"Paragraph:11cb31db39a1_13"},{"__ref":"Paragraph:11cb31db39a1_14"},{"__ref":"Paragraph:11cb31db39a1_15"},{"__ref":"Paragraph:11cb31db39a1_16"},{"__ref":"Paragraph:11cb31db39a1_17"},{"__ref":"Paragraph:11cb31db39a1_18"},{"__ref":"Paragraph:11cb31db39a1_19"},{"__ref":"Paragraph:11cb31db39a1_20"},{"__ref":"Paragraph:11cb31db39a1_21"},{"__ref":"Paragraph:11cb31db39a1_22"},{"__ref":"Paragraph:11cb31db39a1_23"},{"__ref":"Paragraph:11cb31db39a1_24"},{"__ref":"Paragraph:11cb31db39a1_25"},{"__ref":"Paragraph:11cb31db39a1_26"},{"__ref":"Paragraph:11cb31db39a1_27"},{"__ref":"Paragraph:11cb31db39a1_28"},{"__ref":"Paragraph:11cb31db39a1_29"},{"__ref":"Paragraph:11cb31db39a1_30"},{"__ref":"Paragraph:11cb31db39a1_31"},{"__ref":"Paragraph:11cb31db39a1_32"},{"__ref":"Paragraph:11cb31db39a1_33"},{"__ref":"Paragraph:11cb31db39a1_34"},{"__ref":"Paragraph:11cb31db39a1_35"},{"__ref":"Paragraph:11cb31db39a1_36"},{"__ref":"Paragraph:11cb31db39a1_37"},{"__ref":"Paragraph:11cb31db39a1_38"},{"__ref":"Paragraph:11cb31db39a1_39"},{"__ref":"Paragraph:11cb31db39a1_40"},{"__ref":"Paragraph:11cb31db39a1_41"},{"__ref":"Paragraph:11cb31db39a1_42"},{"__ref":"Paragraph:11cb31db39a1_43"},{"__ref":"Paragraph:11cb31db39a1_44"},{"__ref":"Paragraph:11cb31db39a1_45"},{"__ref":"Paragraph:11cb31db39a1_46"},{"__ref":"Paragraph:11cb31db39a1_47"},{"__ref":"Paragraph:11cb31db39a1_48"},{"__ref":"Paragraph:11cb31db39a1_49"},{"__ref":"Paragraph:11cb31db39a1_50"},{"__ref":"Paragraph:11cb31db39a1_51"},{"__ref":"Paragraph:11cb31db39a1_52"},{"__ref":"Paragraph:11cb31db39a1_53"},{"__ref":"Paragraph:11cb31db39a1_54"},{"__ref":"Paragraph:11cb31db39a1_55"},{"__ref":"Paragraph:11cb31db39a1_56"}]}},"customStyleSheet":{"__ref":"CustomStyleSheet:514038af8f2f"},"isPublished":true,"isLocked":false,"license":"ALL_RIGHTS_RESERVED","collaborators":[],"isMarkedPaywallOnly":false,"lockedSource":"LOCKED_POST_SOURCE_NONE","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fa-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53","primaryTopic":{"__ref":"Topic:1eca0103fff3"},"topics":[{"__typename":"Topic","slug":"machine-learning","name":"Machine Learning"},{"__typename":"Topic","slug":"data-science","name":"Data Science"}],"latestPublishedVersion":"11cb31db39a1","postResponses":{"__typename":"PostResponses","count":64},"allowResponses":true,"isLimitedState":false,"voterCount":2758,"recommenders":[],"title":"A Comprehensive Guide to Convolutional Neural Networks — the ELI5 way","clapCount":13278,"statusForCollection":"APPROVED","pinnedAt":0,"pinnedByCreatorAt":1602728429798,"curationEligibleAt":0,"responseDistribution":"NOT_DISTRIBUTED","inResponseToPostResult":null,"inResponseToCatalogResult":null,"pendingCollection":null,"isNewsletter":false,"isAuthorNewsletter":false,"layerCake":3,"tags":[{"__ref":"Tag:convolution-neural-net"},{"__ref":"Tag:tensorflow"},{"__ref":"Tag:computer-vision"},{"__ref":"Tag:machine-learning"},{"__ref":"Tag:deep-learning"}],"sequence":null,"readingTime":6.765094339622642,"inResponseToEntityType":null,"isSeries":false,"uniqueSlug":"a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53","socialTitle":"","socialDek":"","noIndex":null,"curationStatus":"CURATION_STATUS_DISTRIBUTED","metaDescription":"","latestPublishedAt":1545022947450,"previewContent":{"__typename":"PreviewContent","subtitle":"Artificial Intelligence has been witnessing a monumental growth in bridging the gap between the capabilities of humans and machines…"},"previewImage":{"__ref":"ImageMetadata:1*vkQ0hXDaQv57sALXAJquxA.jpeg"},"isShortform":false,"seoTitle":"","updatedAt":1638842842226,"shortformType":"SHORTFORM_TYPE_LINK","seoDescription":"","isIndexable":true,"isSuspended":false,"responseRootPost":{"__typename":"ResponseRootPost","post":{"__ref":"Post:3bd2b1164a53"}},"internalLinks({\"paging\":{\"limit\":8}})":{"__typename":"InternalLinksConnection","items":[{"__ref":"Post:a0dd7885a98"},{"__ref":"Post:b36cfc03ff0a"},{"__ref":"Post:44f6780a4c5"},{"__ref":"Post:22f47b3dc50d"},{"__ref":"Post:8ebe6d16346c"},{"__ref":"Post:a3875eaaa9a3"},{"__ref":"Post:ad0e768fa5f4"},{"__ref":"Post:123f2f2863a6"}]},"awards:countToShowAwardBadge(type:STAFF_PICK,limit:1)":{"__typename":"AwardConnection","totalCount":0,"awards":[]}},"CustomStyleSheet:514038af8f2f":{"__typename":"CustomStyleSheet","id":"514038af8f2f","global":{"__typename":"GlobalStyles","colorPalette":{"__typename":"StyleSheetColorPalette","primary":{"__typename":"ColorValue","colorPalette":{"__typename":"ColorPalette","highlightSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FFEDF4FC","point":0},{"__typename":"ColorPoint","color":"#FFE9F2FD","point":0.1},{"__typename":"ColorPoint","color":"#FFE6F1FD","point":0.2},{"__typename":"ColorPoint","color":"#FFE2EFFD","point":0.3},{"__typename":"ColorPoint","color":"#FFDFEEFD","point":0.4},{"__typename":"ColorPoint","color":"#FFDBECFE","point":0.5},{"__typename":"ColorPoint","color":"#FFD7EBFE","point":0.6},{"__typename":"ColorPoint","color":"#FFD4E9FE","point":0.7},{"__typename":"ColorPoint","color":"#FFD0E7FF","point":0.8},{"__typename":"ColorPoint","color":"#FFCCE6FF","point":0.9},{"__typename":"ColorPoint","color":"#FFC8E4FF","point":1}]},"defaultBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FF668AAA","point":0},{"__typename":"ColorPoint","color":"#FF61809D","point":0.1},{"__typename":"ColorPoint","color":"#FF5A7690","point":0.2},{"__typename":"ColorPoint","color":"#FF546C83","point":0.3},{"__typename":"ColorPoint","color":"#FF4D6275","point":0.4},{"__typename":"ColorPoint","color":"#FF455768","point":0.5},{"__typename":"ColorPoint","color":"#FF3D4C5A","point":0.6},{"__typename":"ColorPoint","color":"#FF34414C","point":0.7},{"__typename":"ColorPoint","color":"#FF2B353E","point":0.8},{"__typename":"ColorPoint","color":"#FF21282F","point":0.9},{"__typename":"ColorPoint","color":"#FF161B1F","point":1}]},"tintBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FF355876","colorPoints":[{"__typename":"ColorPoint","color":"#FF355876","point":0},{"__typename":"ColorPoint","color":"#FF4D6C88","point":0.1},{"__typename":"ColorPoint","color":"#FF637F99","point":0.2},{"__typename":"ColorPoint","color":"#FF7791A8","point":0.3},{"__typename":"ColorPoint","color":"#FF8CA2B7","point":0.4},{"__typename":"ColorPoint","color":"#FF9FB3C6","point":0.5},{"__typename":"ColorPoint","color":"#FFB2C3D4","point":0.6},{"__typename":"ColorPoint","color":"#FFC5D2E1","point":0.7},{"__typename":"ColorPoint","color":"#FFD7E2EE","point":0.8},{"__typename":"ColorPoint","color":"#FFE9F1FA","point":0.9},{"__typename":"ColorPoint","color":"#FFFBFFFF","point":1}]}}},"background":null},"fonts":{"__typename":"StyleSheetFonts","font1":{"__typename":"StyleSheetFont","name":"SANS_SERIF_1"},"font2":{"__typename":"StyleSheetFont","name":"SANS_SERIF_1"},"font3":{"__typename":"StyleSheetFont","name":"SERIF_2"}}},"header":{"__typename":"HeaderStyles","headerScale":"HEADER_SCALE_MEDIUM","backgroundImageDisplayMode":"IMAGE_DISPLAY_MODE_FILL","backgroundImageVerticalAlignment":"CENTER","backgroundColorDisplayMode":"COLOR_DISPLAY_MODE_SOLID","backgroundColor":{"__typename":"ColorValue","alpha":"59","rgb":"355876"},"secondaryBackgroundColor":null,"postBackgroundColor":null,"backgroundImage":{"__ref":"ImageMetadata:1*Pxg5mSUxMauqJj07YJmtdg.png"},"logoImage":{"__ref":"ImageMetadata:1*jGgIXzQHi3stXYzPKNA6Qg.png"},"appNameColor":null,"appNameTreatment":"NAME_TREATMENT_LOGO","nameTreatment":"NAME_TREATMENT_LOGO"},"navigation":{"__typename":"HeaderNavigation","navItems":[{"__typename":"HeaderNavigationItem","name":"Editors' Picks","href":null,"tags":[{"__ref":"Tag:editors-pick"}],"type":"NAV_TYPE_TAG"},{"__typename":"HeaderNavigationItem","name":"Features","href":null,"tags":[{"__ref":"Tag:tds-features"}],"type":"NAV_TYPE_TAG"},{"__typename":"HeaderNavigationItem","name":"Deep Dives","href":null,"tags":[{"__ref":"Tag:deep-dives"}],"type":"NAV_TYPE_TAG"},{"__typename":"HeaderNavigationItem","name":"Author Resources","href":"https:\u002F\u002Ftowardsdatascience.com\u002Fquestions-96667b06af5","tags":[],"type":"NAV_TYPE_LINK"}]}},"ImageMetadata:1*CJe3891yB1A1mzMdqemkdg.jpeg":{"__typename":"ImageMetadata","id":"1*CJe3891yB1A1mzMdqemkdg.jpeg"},"ImageMetadata:1*Pxg5mSUxMauqJj07YJmtdg.png":{"__typename":"ImageMetadata","id":"1*Pxg5mSUxMauqJj07YJmtdg.png","originalWidth":2569},"ImageMetadata:1*jGgIXzQHi3stXYzPKNA6Qg.png":{"__typename":"ImageMetadata","id":"1*jGgIXzQHi3stXYzPKNA6Qg.png","originalHeight":429,"originalWidth":1376},"ImageMetadata:1*mG6i4Bh_LgixUYXJgQpYsg@2x.png":{"__typename":"ImageMetadata","id":"1*mG6i4Bh_LgixUYXJgQpYsg@2x.png","originalHeight":122,"originalWidth":337},"NewsletterV3:d6fe9076899":{"__typename":"NewsletterV3","slug":"the-variable","id":"d6fe9076899","name":"The Variable","description":"Every Thursday, the Variable delivers the very best of Towards Data Science: from hands-on tutorials and cutting-edge research to original features you don't want to miss.","promoHeadline":"","promoBody":"","type":"NEWSLETTER_TYPE_COLLECTION","user":{"__ref":"User:895063a310f4"},"collection":{"__ref":"Collection:7f60cf5620c9"},"showPromo":true},"Tag:editors-pick":{"__typename":"Tag","id":"editors-pick","normalizedTagSlug":"editors-pick"},"Tag:tds-features":{"__typename":"Tag","id":"tds-features","normalizedTagSlug":"tds-features"},"Tag:deep-dives":{"__typename":"Tag","id":"deep-dives","normalizedTagSlug":"deep-dives"},"User:895063a310f4":{"__typename":"User","id":"895063a310f4","name":"Ludovic Benistant","username":"ludobenistant","newsletterV3":{"__ref":"NewsletterV3:2375c85c8da7"}},"NewsletterV3:2375c85c8da7":{"__typename":"NewsletterV3","id":"2375c85c8da7"},"Topic:1eca0103fff3":{"__typename":"Topic","slug":"machine-learning","id":"1eca0103fff3","name":"Machine Learning"},"Paragraph:11cb31db39a1_0":{"__typename":"Paragraph","id":"11cb31db39a1_0","name":"2a13","type":"H3","href":null,"layout":null,"metadata":null,"text":"A Comprehensive Guide to Convolutional Neural Networks — the ELI5 way","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*vkQ0hXDaQv57sALXAJquxA.jpeg":{"__typename":"ImageMetadata","id":"1*vkQ0hXDaQv57sALXAJquxA.jpeg","originalHeight":424,"originalWidth":1255,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:11cb31db39a1_1":{"__typename":"Paragraph","id":"11cb31db39a1_1","name":"8ef9","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*vkQ0hXDaQv57sALXAJquxA.jpeg"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_2":{"__typename":"Paragraph","id":"11cb31db39a1_2","name":"0bac","type":"P","href":null,"layout":null,"metadata":null,"text":"Artificial Intelligence has been witnessing a monumental growth in bridging the gap between the capabilities of humans and machines. Researchers and enthusiasts alike, work on numerous aspects of the field to make amazing things happen. One of many such areas is the domain of Computer Vision.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_3":{"__typename":"Paragraph","id":"11cb31db39a1_3","name":"7431","type":"P","href":null,"layout":null,"metadata":null,"text":"The agenda for this field is to enable machines to view the world as humans do, perceive it in a similar manner and even use the knowledge for a multitude of tasks such as Image & Video recognition, Image Analysis & Classification, Media Recreation, Recommendation Systems, Natural Language Processing, etc. The advancements in Computer Vision with Deep Learning has been constructed and perfected with time, primarily over one particular algorithm — a Convolutional Neural Network.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":453,"end":481,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_4":{"__typename":"Paragraph","id":"11cb31db39a1_4","name":"a61f","type":"H4","href":null,"layout":null,"metadata":null,"text":"Introduction","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*uAeANQIOQPqWZnnuH-VEyw.jpeg":{"__typename":"ImageMetadata","id":"1*uAeANQIOQPqWZnnuH-VEyw.jpeg","originalHeight":880,"originalWidth":1644,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:11cb31db39a1_5":{"__typename":"Paragraph","id":"11cb31db39a1_5","name":"80b1","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*uAeANQIOQPqWZnnuH-VEyw.jpeg"},"text":"A CNN sequence to classify handwritten digits","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_6":{"__typename":"Paragraph","id":"11cb31db39a1_6","name":"fb70","type":"P","href":null,"layout":null,"metadata":null,"text":"A Convolutional Neural Network (ConvNet\u002FCNN) is a Deep Learning algorithm which can take in an input image, assign importance (learnable weights and biases) to various aspects\u002Fobjects in the image and be able to differentiate one from the other. The pre-processing required in a ConvNet is much lower as compared to other classification algorithms. While in primitive methods filters are hand-engineered, with enough training, ConvNets have the ability to learn these filters\u002Fcharacteristics.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":2,"end":44,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_7":{"__typename":"Paragraph","id":"11cb31db39a1_7","name":"ffef","type":"P","href":null,"layout":null,"metadata":null,"text":"The architecture of a ConvNet is analogous to that of the connectivity pattern of Neurons in the Human Brain and was inspired by the organization of the Visual Cortex. Individual neurons respond to stimuli only in a restricted region of the visual field known as the Receptive Field. A collection of such fields overlap to cover the entire visual area.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_8":{"__typename":"Paragraph","id":"11cb31db39a1_8","name":"9dc9","type":"H4","href":null,"layout":null,"metadata":null,"text":"Why ConvNets over Feed-Forward Neural Nets?","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*GLQjM9k0gZ14nYF0XmkRWQ.png":{"__typename":"ImageMetadata","id":"1*GLQjM9k0gZ14nYF0XmkRWQ.png","originalHeight":351,"originalWidth":425,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:11cb31db39a1_9":{"__typename":"Paragraph","id":"11cb31db39a1_9","name":"6c6d","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*GLQjM9k0gZ14nYF0XmkRWQ.png"},"text":"Flattening of a 3x3 image matrix into a 9x1 vector","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_10":{"__typename":"Paragraph","id":"11cb31db39a1_10","name":"6383","type":"P","href":null,"layout":null,"metadata":null,"text":"An image is nothing but a matrix of pixel values, right? So why not just flatten the image (e.g. 3x3 image matrix into a 9x1 vector) and feed it to a Multi-Level Perceptron for classification purposes? Uh.. not really.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_11":{"__typename":"Paragraph","id":"11cb31db39a1_11","name":"df65","type":"P","href":null,"layout":null,"metadata":null,"text":"In cases of extremely basic binary images, the method might show an average precision score while performing prediction of classes but would have little to no accuracy when it comes to complex images having pixel dependencies throughout.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_12":{"__typename":"Paragraph","id":"11cb31db39a1_12","name":"4f1c","type":"P","href":null,"layout":null,"metadata":null,"text":"A ConvNet is able to successfully capture the Spatial and Temporal dependencies in an image through the application of relevant filters. The architecture performs a better fitting to the image dataset due to the reduction in the number of parameters involved and reusability of weights. In other words, the network can be trained to understand the sophistication of the image better.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":21,"end":79,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_13":{"__typename":"Paragraph","id":"11cb31db39a1_13","name":"c380","type":"H4","href":null,"layout":null,"metadata":null,"text":"Input Image","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*15yDvGKV47a0nkf5qLKOOQ.png":{"__typename":"ImageMetadata","id":"1*15yDvGKV47a0nkf5qLKOOQ.png","originalHeight":400,"originalWidth":550,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:11cb31db39a1_14":{"__typename":"Paragraph","id":"11cb31db39a1_14","name":"0c82","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*15yDvGKV47a0nkf5qLKOOQ.png"},"text":"4x4x3 RGB Image","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_15":{"__typename":"Paragraph","id":"11cb31db39a1_15","name":"f21b","type":"P","href":null,"layout":null,"metadata":null,"text":"In the figure, we have an RGB image which has been separated by its three color planes — Red, Green, and Blue. There are a number of such color spaces in which images exist — Grayscale, RGB, HSV, CMYK, etc.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_16":{"__typename":"Paragraph","id":"11cb31db39a1_16","name":"3bb1","type":"P","href":null,"layout":null,"metadata":null,"text":"You can imagine how computationally intensive things would get once the images reach dimensions, say 8K (7680×4320). The role of the ConvNet is to reduce the images into a form which is easier to process, without losing features which are critical for getting a good prediction. This is important when we are to design an architecture which is not only good at learning features but also is scalable to massive datasets.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_17":{"__typename":"Paragraph","id":"11cb31db39a1_17","name":"cad1","type":"H4","href":null,"layout":null,"metadata":null,"text":"Convolution Layer — The Kernel","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*GcI7G-JLAQiEoCON7xFbhg.gif":{"__typename":"ImageMetadata","id":"1*GcI7G-JLAQiEoCON7xFbhg.gif","originalHeight":384,"originalWidth":526,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:11cb31db39a1_18":{"__typename":"Paragraph","id":"11cb31db39a1_18","name":"9eb5","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*GcI7G-JLAQiEoCON7xFbhg.gif"},"text":"Convoluting a 5x5x1 image with a 3x3x1 kernel to get a 3x3x1 convolved feature","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_19":{"__typename":"Paragraph","id":"11cb31db39a1_19","name":"0f71","type":"P","href":null,"layout":null,"metadata":null,"text":"Image Dimensions = 5 (Height) x 5 (Breadth) x 1 (Number of channels, eg. RGB)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_20":{"__typename":"Paragraph","id":"11cb31db39a1_20","name":"9be0","type":"P","href":null,"layout":null,"metadata":null,"text":"In the above demonstration, the green section resembles our 5x5x1 input image, I. The element involved in carrying out the convolution operation in the first part of a Convolutional Layer is called the Kernel\u002FFilter, K, represented in the color yellow. We have selected K as a 3x3x1 matrix.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":60,"end":80,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":202,"end":218,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":270,"end":290,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_21":{"__typename":"Paragraph","id":"11cb31db39a1_21","name":"e9b7","type":"PRE","href":null,"layout":null,"metadata":null,"text":"Kernel\u002FFilter, K = ","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_22":{"__typename":"Paragraph","id":"11cb31db39a1_22","name":"63d3","type":"PRE","href":null,"layout":null,"metadata":null,"text":"1  0  1\n0  1  0\n1  0  1","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_23":{"__typename":"Paragraph","id":"11cb31db39a1_23","name":"b923","type":"P","href":null,"layout":null,"metadata":null,"text":"The Kernel shifts 9 times because of Stride Length = 1 (Non-Strided), every time performing a matrix multiplication operation between K and the portion P of the image over which the kernel is hovering.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":37,"end":68,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":94,"end":166,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*NsiYxt8tPDQyjyH3C08PVA@2x.png":{"__typename":"ImageMetadata","id":"1*NsiYxt8tPDQyjyH3C08PVA@2x.png","originalHeight":463,"originalWidth":326,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:11cb31db39a1_24":{"__typename":"Paragraph","id":"11cb31db39a1_24","name":"22d1","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*NsiYxt8tPDQyjyH3C08PVA@2x.png"},"text":"Movement of the Kernel","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_25":{"__typename":"Paragraph","id":"11cb31db39a1_25","name":"e26f","type":"P","href":null,"layout":null,"metadata":null,"text":"The filter moves to the right with a certain Stride Value till it parses the complete width. Moving on, it hops down to the beginning (left) of the image with the same Stride Value and repeats the process until the entire image is traversed.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*ciDgQEjViWLnCbmX-EeSrA.gif":{"__typename":"ImageMetadata","id":"1*ciDgQEjViWLnCbmX-EeSrA.gif","originalHeight":720,"originalWidth":1280,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:11cb31db39a1_26":{"__typename":"Paragraph","id":"11cb31db39a1_26","name":"3068","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*ciDgQEjViWLnCbmX-EeSrA.gif"},"text":"Convolution operation on a MxNx3 image matrix with a 3x3x3 Kernel","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_27":{"__typename":"Paragraph","id":"11cb31db39a1_27","name":"54cb","type":"P","href":null,"layout":null,"metadata":null,"text":"In the case of images with multiple channels (e.g. RGB), the Kernel has the same depth as that of the input image. Matrix Multiplication is performed between Kn and In stack ([K1, I1]; [K2, I2]; [K3, I3]) and all the results are summed with the bias to give us a squashed one-depth channel Convoluted Feature Output.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*1VJDP6qDY9-ExTuQVEOlVg.gif":{"__typename":"ImageMetadata","id":"1*1VJDP6qDY9-ExTuQVEOlVg.gif","originalHeight":381,"originalWidth":395,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:11cb31db39a1_28":{"__typename":"Paragraph","id":"11cb31db39a1_28","name":"cd33","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*1VJDP6qDY9-ExTuQVEOlVg.gif"},"text":"Convolution Operation with Stride Length = 2","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_29":{"__typename":"Paragraph","id":"11cb31db39a1_29","name":"a57a","type":"P","href":null,"layout":null,"metadata":null,"text":"The objective of the Convolution Operation is to extract the high-level features such as edges, from the input image. ConvNets need not be limited to only one Convolutional Layer. Conventionally, the first ConvLayer is responsible for capturing the Low-Level features such as edges, color, gradient orientation, etc. With added layers, the architecture adapts to the High-Level features as well, giving us a network which has the wholesome understanding of images in the dataset, similar to how we would.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":49,"end":80,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_30":{"__typename":"Paragraph","id":"11cb31db39a1_30","name":"7f9d","type":"P","href":null,"layout":null,"metadata":null,"text":"There are two types of results to the operation — one in which the convolved feature is reduced in dimensionality as compared to the input, and the other in which the dimensionality is either increased or remains the same. This is done by applying Valid Padding in case of the former, or Same Padding in the case of the latter.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":248,"end":261,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":288,"end":300,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*nYf_cUIHFEWU1JXGwnz-Ig.gif":{"__typename":"ImageMetadata","id":"1*nYf_cUIHFEWU1JXGwnz-Ig.gif","originalHeight":449,"originalWidth":395,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:11cb31db39a1_31":{"__typename":"Paragraph","id":"11cb31db39a1_31","name":"e0ec","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*nYf_cUIHFEWU1JXGwnz-Ig.gif"},"text":"SAME padding: 5x5x1 image is padded with 0s to create a 6x6x1 image","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":13,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_32":{"__typename":"Paragraph","id":"11cb31db39a1_32","name":"8652","type":"P","href":null,"layout":null,"metadata":null,"text":"When we augment the 5x5x1 image into a 6x6x1 image and then apply the 3x3x1 kernel over it, we find that the convolved matrix turns out to be of dimensions 5x5x1. Hence the name — Same Padding.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":180,"end":192,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_33":{"__typename":"Paragraph","id":"11cb31db39a1_33","name":"7bb2","type":"P","href":null,"layout":null,"metadata":null,"text":"On the other hand, if we perform the same operation without padding, we are presented with a matrix which has dimensions of the Kernel (3x3x1) itself — Valid Padding.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":152,"end":165,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_34":{"__typename":"Paragraph","id":"11cb31db39a1_34","name":"8d12","type":"P","href":null,"layout":null,"metadata":null,"text":"The following repository houses many such GIFs which would help you get a better understanding of how Padding and Stride Length work together to achieve results relevant to our needs.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_35":{"__typename":"Paragraph","id":"11cb31db39a1_35","name":"f065","type":"MIXTAPE_EMBED","href":null,"layout":null,"metadata":null,"text":"vdumoulin\u002Fconv_arithmetic\nA technical report on convolution arithmetic in the context of deep learning - vdumoulin\u002Fconv_arithmeticgithub.com","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":140,"href":"https:\u002F\u002Fgithub.com\u002Fvdumoulin\u002Fconv_arithmetic","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":25,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":26,"end":130,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":{"__typename":"MixtapeMetadata","href":"https:\u002F\u002Fgithub.com\u002Fvdumoulin\u002Fconv_arithmetic","mediaResource":{"__typename":"MediaResource","mediumCatalog":null},"thumbnailImageId":"0*aanOJtoccyFd7bk_"}},"Paragraph:11cb31db39a1_36":{"__typename":"Paragraph","id":"11cb31db39a1_36","name":"333b","type":"H4","href":null,"layout":null,"metadata":null,"text":"Pooling Layer","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*uoWYsCV5vBU8SHFPAPao-w.gif":{"__typename":"ImageMetadata","id":"1*uoWYsCV5vBU8SHFPAPao-w.gif","originalHeight":248,"originalWidth":396,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:11cb31db39a1_37":{"__typename":"Paragraph","id":"11cb31db39a1_37","name":"6a33","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*uoWYsCV5vBU8SHFPAPao-w.gif"},"text":"3x3 pooling over 5x5 convolved feature","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_38":{"__typename":"Paragraph","id":"11cb31db39a1_38","name":"6015","type":"P","href":null,"layout":null,"metadata":null,"text":"Similar to the Convolutional Layer, the Pooling layer is responsible for reducing the spatial size of the Convolved Feature. This is to decrease the computational power required to process the data through dimensionality reduction. Furthermore, it is useful for extracting dominant features which are rotational and positional invariant, thus maintaining the process of effectively training of the model.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":136,"end":197,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":262,"end":290,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_39":{"__typename":"Paragraph","id":"11cb31db39a1_39","name":"6ee5","type":"P","href":null,"layout":null,"metadata":null,"text":"There are two types of Pooling: Max Pooling and Average Pooling. Max Pooling returns the maximum value from the portion of the image covered by the Kernel. On the other hand, Average Pooling returns the average of all the values from the portion of the image covered by the Kernel.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":65,"end":76,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":89,"end":102,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":175,"end":191,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":203,"end":229,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_40":{"__typename":"Paragraph","id":"11cb31db39a1_40","name":"b9da","type":"P","href":null,"layout":null,"metadata":null,"text":"Max Pooling also performs as a Noise Suppressant. It discards the noisy activations altogether and also performs de-noising along with dimensionality reduction. On the other hand, Average Pooling simply performs dimensionality reduction as a noise suppressing mechanism. Hence, we can say that Max Pooling performs a lot better than Average Pooling.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":30,"end":48,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":294,"end":348,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*KQIEqhxzICU7thjaQBfPBQ.png":{"__typename":"ImageMetadata","id":"1*KQIEqhxzICU7thjaQBfPBQ.png","originalHeight":439,"originalWidth":596,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:11cb31db39a1_41":{"__typename":"Paragraph","id":"11cb31db39a1_41","name":"d00b","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*KQIEqhxzICU7thjaQBfPBQ.png"},"text":"Types of Pooling","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_42":{"__typename":"Paragraph","id":"11cb31db39a1_42","name":"6915","type":"P","href":null,"layout":null,"metadata":null,"text":"The Convolutional Layer and the Pooling Layer, together form the i-th layer of a Convolutional Neural Network. Depending on the complexities in the images, the number of such layers may be increased for capturing low-levels details even further, but at the cost of more computational power.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_43":{"__typename":"Paragraph","id":"11cb31db39a1_43","name":"3751","type":"P","href":null,"layout":null,"metadata":null,"text":"After going through the above process, we have successfully enabled the model to understand the features. Moving on, we are going to flatten the final output and feed it to a regular Neural Network for classification purposes.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_44":{"__typename":"Paragraph","id":"11cb31db39a1_44","name":"82e5","type":"H4","href":null,"layout":null,"metadata":null,"text":"Classification — Fully Connected Layer (FC Layer)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*kToStLowjokojIQ7pY2ynQ.jpeg":{"__typename":"ImageMetadata","id":"1*kToStLowjokojIQ7pY2ynQ.jpeg","originalHeight":467,"originalWidth":802,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:11cb31db39a1_45":{"__typename":"Paragraph","id":"11cb31db39a1_45","name":"99c2","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*kToStLowjokojIQ7pY2ynQ.jpeg"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_46":{"__typename":"Paragraph","id":"11cb31db39a1_46","name":"7432","type":"P","href":null,"layout":null,"metadata":null,"text":"Adding a Fully-Connected layer is a (usually) cheap way of learning non-linear combinations of the high-level features as represented by the output of the convolutional layer. The Fully-Connected layer is learning a possibly non-linear function in that space.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_47":{"__typename":"Paragraph","id":"11cb31db39a1_47","name":"2f60","type":"P","href":null,"layout":null,"metadata":null,"text":"Now that we have converted our input image into a suitable form for our Multi-Level Perceptron, we shall flatten the image into a column vector. The flattened output is fed to a feed-forward neural network and backpropagation applied to every iteration of training. Over a series of epochs, the model is able to distinguish between dominating and certain low-level features in images and classify them using the Softmax Classification technique.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":412,"end":434,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_48":{"__typename":"Paragraph","id":"11cb31db39a1_48","name":"53a6","type":"P","href":null,"layout":null,"metadata":null,"text":"There are various architectures of CNNs available which have been key in building algorithms which power and shall power AI as a whole in the foreseeable future. Some of them have been listed below:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_49":{"__typename":"Paragraph","id":"11cb31db39a1_49","name":"b784","type":"OLI","href":null,"layout":null,"metadata":null,"text":"LeNet","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_50":{"__typename":"Paragraph","id":"11cb31db39a1_50","name":"2ba9","type":"OLI","href":null,"layout":null,"metadata":null,"text":"AlexNet","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_51":{"__typename":"Paragraph","id":"11cb31db39a1_51","name":"3f07","type":"OLI","href":null,"layout":null,"metadata":null,"text":"VGGNet","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_52":{"__typename":"Paragraph","id":"11cb31db39a1_52","name":"e514","type":"OLI","href":null,"layout":null,"metadata":null,"text":"GoogLeNet","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_53":{"__typename":"Paragraph","id":"11cb31db39a1_53","name":"735c","type":"OLI","href":null,"layout":null,"metadata":null,"text":"ResNet","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_54":{"__typename":"Paragraph","id":"11cb31db39a1_54","name":"b68a","type":"OLI","href":null,"layout":null,"metadata":null,"text":"ZFNet","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_55":{"__typename":"Paragraph","id":"11cb31db39a1_55","name":"9c7d","type":"P","href":null,"layout":null,"metadata":null,"text":"GitHub Notebook — Recognising Hand Written Digits using MNIST Dataset with TensorFlow","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":85,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:11cb31db39a1_56":{"__typename":"Paragraph","id":"11cb31db39a1_56","name":"cf8f","type":"MIXTAPE_EMBED","href":null,"layout":null,"metadata":null,"text":"ss-is-master-chief\u002FMNIST-Digit.Recognizer-CNNs\nImplementation of CNN to recognize hand written digits (MNIST) running for 10 epochs. Accuracy: 98.99% …github.com","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":161,"href":"https:\u002F\u002Fgithub.com\u002Fss-is-master-chief\u002FMNIST-Digit.Recognizer-CNNs","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":46,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":47,"end":151,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":{"__typename":"MixtapeMetadata","href":"https:\u002F\u002Fgithub.com\u002Fss-is-master-chief\u002FMNIST-Digit.Recognizer-CNNs","mediaResource":{"__typename":"MediaResource","mediumCatalog":null},"thumbnailImageId":"0*9DL3pUPHcomdTt5h"}},"CollectionViewerEdge:collectionId:7f60cf5620c9-viewerId:lo_ff0caccbcd02":{"__typename":"CollectionViewerEdge","id":"collectionId:7f60cf5620c9-viewerId:lo_ff0caccbcd02","isEditor":false},"User:7e12c71dfa81":{"__typename":"User","id":"7e12c71dfa81","atsQualifiedAt":1612205680542},"Tag:convolution-neural-net":{"__typename":"Tag","id":"convolution-neural-net"},"Tag:tensorflow":{"__typename":"Tag","id":"tensorflow"},"Tag:computer-vision":{"__typename":"Tag","id":"computer-vision"},"Tag:machine-learning":{"__typename":"Tag","id":"machine-learning"},"Tag:deep-learning":{"__typename":"Tag","id":"deep-learning"},"User:9480ce2d902d":{"__typename":"User","id":"9480ce2d902d","imageId":"","mediumMemberAt":0,"name":"Viraj Kadam","username":"viraajkadam","customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"viraajkadam.medium.com"}},"hasSubdomain":true,"bio":""},"ImageMetadata:1*ZTWffsdfQFebOcwTB2IEzg.png":{"__typename":"ImageMetadata","id":"1*ZTWffsdfQFebOcwTB2IEzg.png","alt":null,"focusPercentX":null,"focusPercentY":null},"Post:a0dd7885a98":{"__typename":"Post","id":"a0dd7885a98","visibility":"PUBLIC","previewContent":{"__typename":"PreviewContent","isFullContent":false,"subtitle":"Using custom functions for doing some preprocessing of input data in tf data pipelines can be a daunting task, especially if you don’t know…"},"collection":null,"title":"Loading Multi-band satellite images in tensorflow data pipelines","mediumUrl":"https:\u002F\u002Fviraajkadam.medium.com\u002Floading-multi-band-satellite-images-in-tensorflow-data-pipelines-a0dd7885a98","creator":{"__ref":"User:9480ce2d902d"},"previewImage":{"__ref":"ImageMetadata:1*ZTWffsdfQFebOcwTB2IEzg.png"},"clapCount":5,"isSeries":false,"sequence":null,"uniqueSlug":"loading-multi-band-satellite-images-in-tensorflow-data-pipelines-a0dd7885a98"},"User:eb6de8718f32":{"__typename":"User","id":"eb6de8718f32","imageId":"1*yBu5aDVYFXqHujp5SRgb8w.jpeg","mediumMemberAt":0,"name":"Luke Menzies","username":"lukemenzies","customDomainState":null,"hasSubdomain":false,"bio":""},"ImageMetadata:1*SiQ6IOXfcTjT4bQdUPewnA.png":{"__typename":"ImageMetadata","id":"1*SiQ6IOXfcTjT4bQdUPewnA.png","alt":null,"focusPercentX":null,"focusPercentY":null},"Post:b36cfc03ff0a":{"__typename":"Post","id":"b36cfc03ff0a","visibility":"PUBLIC","previewContent":{"__typename":"PreviewContent","isFullContent":false,"subtitle":"Many businesses recognise the benefits of Artificial Intelligence (AI) and Machine Learning (ML) for boosting the potential of their data…"},"collection":null,"title":"Distil8 — Solution Accelerators","mediumUrl":"https:\u002F\u002Fmedium.com\u002F@lukemenzies\u002Fdistil8-solution-accelerators-b36cfc03ff0a","creator":{"__ref":"User:eb6de8718f32"},"previewImage":{"__ref":"ImageMetadata:1*SiQ6IOXfcTjT4bQdUPewnA.png"},"clapCount":3,"isSeries":false,"sequence":null,"uniqueSlug":"distil8-solution-accelerators-b36cfc03ff0a"},"User:347ee69b6143":{"__typename":"User","id":"347ee69b6143","imageId":"0*faBhW5Ch94aNWl68","mediumMemberAt":0,"name":"David C Exiga","username":"david-exiga","customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"david-exiga.medium.com"}},"hasSubdomain":true,"bio":""},"ImageMetadata:0*tcx2eTZLxxpy1ncK":{"__typename":"ImageMetadata","id":"0*tcx2eTZLxxpy1ncK","alt":null,"focusPercentX":null,"focusPercentY":null},"Post:44f6780a4c5":{"__typename":"Post","id":"44f6780a4c5","visibility":"PUBLIC","previewContent":{"__typename":"PreviewContent","isFullContent":false,"subtitle":""},"collection":null,"title":"Music Generation Using LSTM Neural Networks","mediumUrl":"https:\u002F\u002Fdavid-exiga.medium.com\u002Fmusic-generation-using-lstm-neural-networks-44f6780a4c5","creator":{"__ref":"User:347ee69b6143"},"previewImage":{"__ref":"ImageMetadata:0*tcx2eTZLxxpy1ncK"},"clapCount":1,"isSeries":false,"sequence":null,"uniqueSlug":"music-generation-using-lstm-neural-networks-44f6780a4c5"},"Collection:1f080c3ceb95":{"__typename":"Collection","id":"1f080c3ceb95","slug":"weareservian","name":"Servian","domain":"servian.dev"},"User:5b9d774599eb":{"__typename":"User","id":"5b9d774599eb","imageId":"1*swNF-1ZWqMmJR52Tp2K1_A.png","mediumMemberAt":0,"name":"Matthew Grey","username":"matthew-g","customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"matthew-g.medium.com"}},"hasSubdomain":true,"bio":"Technology engineer keen on big data, automation, streaming, and natural language processing. Currently focused on solutions in Google Cloud."},"ImageMetadata:1*PpvYTXsVy9vPZSkzlZ6QcQ.jpeg":{"__typename":"ImageMetadata","id":"1*PpvYTXsVy9vPZSkzlZ6QcQ.jpeg","alt":"A library bookshelf","focusPercentX":null,"focusPercentY":null},"Post:22f47b3dc50d":{"__typename":"Post","id":"22f47b3dc50d","visibility":"PUBLIC","previewContent":{"__typename":"PreviewContent","isFullContent":false,"subtitle":"How to quickly and easily experiment with advanced NLP in the cloud with Google Cloud and Machine Learning"},"collection":{"__ref":"Collection:1f080c3ceb95"},"title":"Automating Document Comprehension in One Week","mediumUrl":"https:\u002F\u002Fservian.dev\u002Fautomating-document-comprehension-in-one-week-22f47b3dc50d","creator":{"__ref":"User:5b9d774599eb"},"previewImage":{"__ref":"ImageMetadata:1*PpvYTXsVy9vPZSkzlZ6QcQ.jpeg"},"clapCount":54,"isSeries":false,"sequence":null,"uniqueSlug":"automating-document-comprehension-in-one-week-22f47b3dc50d"},"User:dcae39a0060":{"__typename":"User","id":"dcae39a0060","imageId":"1*UsdNYRSsr8YMyQpSmpNxZA@2x.jpeg","mediumMemberAt":0,"name":"Alan Ratliff","username":"alan-ratliff","customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"alan-ratliff.medium.com"}},"hasSubdomain":true,"bio":""},"ImageMetadata:1*rkH7AepwMs2eoPSxLG2L_Q.png":{"__typename":"ImageMetadata","id":"1*rkH7AepwMs2eoPSxLG2L_Q.png","alt":null,"focusPercentX":null,"focusPercentY":null},"Post:8ebe6d16346c":{"__typename":"Post","id":"8ebe6d16346c","visibility":"PUBLIC","previewContent":{"__typename":"PreviewContent","isFullContent":false,"subtitle":"The 2020 election season is over and all of the characteristics of election season has gone with it. We are now free from tv…"},"collection":null,"title":"Using Supervised Machine Learning in Elections","mediumUrl":"https:\u002F\u002Falan-ratliff.medium.com\u002Fusing-supervised-machine-learning-in-elections-8ebe6d16346c","creator":{"__ref":"User:dcae39a0060"},"previewImage":{"__ref":"ImageMetadata:1*rkH7AepwMs2eoPSxLG2L_Q.png"},"clapCount":300,"isSeries":false,"sequence":null,"uniqueSlug":"using-supervised-machine-learning-in-elections-8ebe6d16346c"},"User:dc3315c1261a":{"__typename":"User","id":"dc3315c1261a","imageId":"1*bMfUiKGXjiHAiIG-yvz_6A.png","mediumMemberAt":0,"name":"Vitality Learning","username":"vitalitylearning","customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"vitalitylearning.medium.com"}},"hasSubdomain":true,"bio":"We are teaching, researching and consulting parallel programming on Graphics Processing Units (GPUs) since the delivery of CUDA. We also play Matlab and Python."},"ImageMetadata:0*9ZuzIFdaa3aC3l-r":{"__typename":"ImageMetadata","id":"0*9ZuzIFdaa3aC3l-r","alt":null,"focusPercentX":null,"focusPercentY":null},"Post:a3875eaaa9a3":{"__typename":"Post","id":"a3875eaaa9a3","visibility":"PUBLIC","previewContent":{"__typename":"PreviewContent","isFullContent":false,"subtitle":"The k-Nearest Neighbors (KNN) algorithm is a supervised learning algorithm and one of the best known and most used approaches in machine…"},"collection":null,"title":"Nearest neighbor with TensorFlow","mediumUrl":"https:\u002F\u002Fvitalitylearning.medium.com\u002Fnearest-neighbor-with-tensorflow-a3875eaaa9a3","creator":{"__ref":"User:dc3315c1261a"},"previewImage":{"__ref":"ImageMetadata:0*9ZuzIFdaa3aC3l-r"},"clapCount":6,"isSeries":false,"sequence":null,"uniqueSlug":"nearest-neighbor-with-tensorflow-a3875eaaa9a3"},"User:93f4f3e7d553":{"__typename":"User","id":"93f4f3e7d553","imageId":"0*j_lisS9Lwr_zDiBl","mediumMemberAt":0,"name":"Jeyasri Subramanian","username":"jeyasrisubramanian","customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"jeyasrisubramanian.medium.com"}},"hasSubdomain":true,"bio":""},"ImageMetadata:1*jPWFkuY3F5UAqT_809FMOA.png":{"__typename":"ImageMetadata","id":"1*jPWFkuY3F5UAqT_809FMOA.png","alt":null,"focusPercentX":null,"focusPercentY":null},"Post:ad0e768fa5f4":{"__typename":"Post","id":"ad0e768fa5f4","visibility":"PUBLIC","previewContent":{"__typename":"PreviewContent","isFullContent":false,"subtitle":"Generalizing from a Few Examples: Few-Shot"},"collection":null,"title":"A survey on Few shot learning","mediumUrl":"https:\u002F\u002Fjeyasrisubramanian.medium.com\u002Fa-survey-on-few-shot-learning-ad0e768fa5f4","creator":{"__ref":"User:93f4f3e7d553"},"previewImage":{"__ref":"ImageMetadata:1*jPWFkuY3F5UAqT_809FMOA.png"},"clapCount":1,"isSeries":false,"sequence":null,"uniqueSlug":"a-survey-on-few-shot-learning-ad0e768fa5f4"},"User:b9640a719f7d":{"__typename":"User","id":"b9640a719f7d","imageId":"0*dokdoY4LnZq0FJDB","mediumMemberAt":0,"name":"Ricardo Garcia","username":"ragsec0","customDomainState":null,"hasSubdomain":false,"bio":"Economist — Data Analyst — Entrepreneur"},"ImageMetadata:1*Ipw5BmOTkawjtjLEB0DtxQ.png":{"__typename":"ImageMetadata","id":"1*Ipw5BmOTkawjtjLEB0DtxQ.png","alt":null,"focusPercentX":null,"focusPercentY":null},"Post:123f2f2863a6":{"__typename":"Post","id":"123f2f2863a6","visibility":"PUBLIC","previewContent":{"__typename":"PreviewContent","isFullContent":false,"subtitle":"Introduction"},"collection":null,"title":"Attention is all you need: A gentle explanation for The Transformers model.","mediumUrl":"https:\u002F\u002Fmedium.com\u002F@ragsec0\u002Fattention-is-all-you-need-a-gentle-explanation-for-the-transformers-model-123f2f2863a6","creator":{"__ref":"User:b9640a719f7d"},"previewImage":{"__ref":"ImageMetadata:1*Ipw5BmOTkawjtjLEB0DtxQ.png"},"clapCount":14,"isSeries":false,"sequence":null,"uniqueSlug":"attention-is-all-you-need-a-gentle-explanation-for-the-transformers-model-123f2f2863a6"}}</script><script>window.__MIDDLEWARE_STATE__={"session":{"xsrf":"da15ac5c6ada"},"cache":{"cacheStatus":"HIT","inDisabledExperiment":false}}</script><script src="https://cdn-client.medium.com/lite/static/js/manifest.4900d295.js"></script><script src="https://cdn-client.medium.com/lite/static/js/3034.5bf7db30.js"></script><script src="https://cdn-client.medium.com/lite/static/js/main.0df07f4d.js"></script><script src="https://cdn-client.medium.com/lite/static/js/instrumentation.c71f0248.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8732.9d4e0df2.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/3447.cd943c14.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/AppLayout.d5bc1f29.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/reporting.bbdcaa9d.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/4270.c0f5b685.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/1752.a348f767.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/1961.72b183c8.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5472.a7dd22a2.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/1566.98f91aa2.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2981.3c13b705.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/7592.07b5ec72.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/3115.02da9f5b.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/4869.c26b42a4.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9401.492bc814.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2307.b2a54ca4.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/7070.83cd757a.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9442.5291e270.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/4483.f9c22ca1.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/210.1b33e4a9.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/864.dc58ca67.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/1618.68e77d4c.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2519.cd863424.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/3610.76bcab8d.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/4897.9582ba06.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6912.bfde0b6f.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8051.aeff6f97.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9241.4c93753b.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/3443.f4bfcd80.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5754.6687b8d5.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/PostPage.MainContent.68be6335.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8261.d872e38a.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5180.1a76bff3.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/7994.bf2b36c9.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/PostPage.RightColumnContent.6b18967f.chunk.js"></script><script>window.main();</script><script defer src="https://static.cloudflareinsights.com/beacon.min.js/vaafb692b2aea4879b33c060e79fe94621666317369993" integrity="sha512-0ahDYl866UMhKuYcW078ScMalXqtFJggm7TmlUtp0UlD4eQk0Ixfnm5ykXKvGJNFjLMoortdseTfsRT8oCfgGA==" data-cf-beacon='{"rayId":"761e908dec4f3378","token":"0b5f665943484354a59c39c6833f7078","version":"2022.10.3","si":100}' crossorigin="anonymous"></script>
</body></html>